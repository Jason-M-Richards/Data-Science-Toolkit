{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Basics\n",
    "Venn Diagram page showing set operations\n",
    "https://www.onlinemathlearning.com/shading-venn-diagrams.html\n",
    "\n",
    "- Universal Set - all possible outcomes in a universe \n",
    "- Empty set - no elements in the set\n",
    "\n",
    "### Inclusion/Exclusion Principle\n",
    "\n",
    "Note that if we want to know how many elements are in set $S$ versus $T$ we cannot simply sum up the elements, because they have elements in common.\n",
    "\n",
    "In combinational mathematics, the inclusion-exclusion principle is a counting technique solve this problem.\n",
    "\n",
    "When having 2 sets, the method for obtaining the union of two finite sets is given by:\n",
    "\n",
    "$\\mid S \\cup T \\mid = \\mid S \\mid + \\mid T \\mid - \\mid S \\cap T \\mid $\n",
    "\n",
    "Where the horizontal lines denote the *cardinality* of a set, which is the number of elements, considering a finite set. \n",
    "\n",
    "The formula expresses the fact that the sum of the sizes of the two sets may be too large since some elements may be counted twice. For the double-counted elements, one is substracted again.\n",
    "\n",
    "This formula can be extended to three sets, four sets, etc. Imagine we have a third set $R$:\n",
    "\n",
    "$\\mid S \\cup T\\cup R \\mid = \\mid S \\mid + \\mid T \\mid + \\mid R \\mid - \\mid S \\cap T \\mid  -\\mid S \\cap R \\mid - \\mid R \\cap T \\mid  + \\mid S \\cap T \\cap R \\mid $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Methods and Operations\n",
    "\n",
    "| Method        |\tEquivalent |\tResult |\n",
    "| ------                    | ------       | ------    |\n",
    "| s.issubset(t)             |\ts <= t     | test whether every element in s is in t\n",
    "| s.issuperset(t)           |\ts >= t     | test whether every element in t is in s\n",
    "| s.union(t)                |\ts $\\mid$ t | new set with elements from both s and t\n",
    "| s.intersection(t)         |\ts & t      | new set with elements common to s and t\n",
    "| s.difference(t)           |\ts - t \t   | new set with elements in s but not in t\n",
    "| s.symmetric_difference(t) |\ts ^ t      | new set with elements in either s or t but not both\n",
    "\n",
    "|Operation                          |\tEquivalent |\tResult|\n",
    "| ------                            | ------       | ------   |\n",
    "|s.update(t)                        | \t$s \\mid t$ \t   |return set s with elements added from t|\n",
    "|s.intersection_update(t)           | \ts &= t     |\treturn set s keeping only elements also found in t|\n",
    "|s.difference_update(t)             |\ts -= t \t   |return set s after removing elements found in t|\n",
    "|s.symmetric_difference_update(t)   |\ts ^= t \t   |return set s with elements from s or t but not both|\n",
    "|s.add(x)                           |\t           |\tadd element x to set s|\n",
    "|s.remove(x)                        |\t           |\tremove x from set s|\n",
    "|s.discard(x)                       |\t           |\tremoves x from set s if present|\n",
    "|s.pop()                            | \t           |\tremove and return an arbitrary element from s|\n",
    "|s.clear()            \t            |  \t           |remove all elements from set s|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Fundamentals\n",
    "\n",
    "#### Experiment and outcomes¶\n",
    "S={1,2,3,4,5,6} being the possible outcomes when throwing a dice.\n",
    "\n",
    "In this context, we'd call throwing the dice a random experiment. The result of this experiment is then called the outcome. Note that SS defines all the possible outcomes when throwing the dice once, so in fact, we can also call it the Universal set Ω, as seen before.\n",
    "\n",
    "In the context of experiments, we denote S the sample space.\n",
    "\n",
    "Other examples of sample spaces:\n",
    "\n",
    "- Number of text messages a day: S={x∣x∈ℤ,x≥0}\n",
    "- Hours of TV a day: S={x∣x∈ℝ,0≤x≤24}\n",
    "\n",
    "#### Event space\n",
    "In this context, we can also define the event space. The event space is a subset of the sample space, E⊆SE⊆S\n",
    "\n",
    "For example, the event \"throwing a number higher than 4\" would result in an event space E={5,6}. Throwing an odd number would lead to an event space E={1,3,5}.\n",
    "\n",
    "Summarized, the event space is a collection of events that we care about. We say that event E happened if the actual outcome after rolling the dice belongs to the predefined event space E.\n",
    "\n",
    "Using the concepts of sample space and event space, we can now introduce the concept of probability.\n",
    "\n",
    "Other examples of event spaces based on previously defined sample spaces:\n",
    "\n",
    "- Low text message volume day: E={x∣x∈ℤ,0≤x≤20}\n",
    "- Bingewatch day: E={x∣x∈ℝ,x≥6}\n",
    "\n",
    "#### Introduction to probability\n",
    "\n",
    "##### The law of relative frequency\n",
    "While conducting an endless stream of experiments, the relative frequency by which an event will happen becomes a fixed number.\n",
    "\n",
    "Let's denote an event E, and P(E) the probability of E occurring. Next, let nn be the number of conducted experiments, and S(n) the count of \"succesful\" experiments (i.e. the times that event E happend). The formal definition of probability as a relative frequency is given by:\n",
    "\n",
    "P(E)=limn→∞S(n)n\n",
    "\n",
    "This is the basis of a frequentist statistical interpretation: an events probability is the ratio of the positive trails to the total number of trials as we repeat the process infinitely.\n",
    "\n",
    "For example, the probability of rolling a 5 on a 6 sided dice is the limit of the successes to trials as the number of trials goes to infinity.\n",
    "\n",
    "In the early 20th century, Kolmogorov and Von Mises came up with 3 axioms that further expand upon this notion.\n",
    "\n",
    "#### Probability axioms\n",
    "\n",
    "\n",
    "1. Positivity\n",
    "A probability is always bigger than or equal to 0, or 0≤P(E)≤10≤P(E)≤1\n",
    "\n",
    "2. Probability of a certain event\n",
    "If the event of interest is the sample space, we say that the outcome is a certain event, or P(S)=1P(S)=1\n",
    "\n",
    "3. Additivity\n",
    "The probability of the union of 2 exclusive events is equal to the sum of the probabilities of the individual events happening.\n",
    "\n",
    "If A∩B=∅, then P(A∪B)=P(A)+P(B)\n",
    "\n",
    "#### Addition law of probability\n",
    "The additivity axiom is great, but most of the time events are not exclusive. A very important proberty is the addition law or probability or the sum rule.\n",
    "\n",
    "P(A∪B)=P(A)+P(B)−P(A∩B)\n",
    "\n",
    "Put in words, the probability that A or B will happen is the sum of the probabilities that A will happen and that B will happen, minus the probability that both A and B will happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutations\n",
    "\n",
    "The problem setting in general is that, there are $n$ objects, and we want to know how many *permutations* are possible.\n",
    "\n",
    "This is a way how you can tackle this. You're the front singer and have to decide which song to play first. You have 3 songs to choose from, so 3 ways of chosing a first song. Then, you move on to the second song. You've chosen the first one, so you have 2 songs to choose from now. Etcetera. Mathematically, this boils down to:\n",
    " $ \\text{# Jackson permutations} = 3*2*1 = 3 ! = 6$\n",
    " \n",
    " ### Permutations of a Subset\n",
    " \n",
    " Now, lets consider another example. \"Who's bad\" is still playing a concert at central park, but the disagree on the final three songs that they will play. They only get a 12min gig slot, so they really can't play more than 3, yet they have a shortlist of 8 they need to pick from. How many final song selections are possible given this info? As for the first example, the order of the songs played is still important.\n",
    "\n",
    "When the band members decide on the first song, they have 8 possible songs to choose from. When chosing the second song, they have 7 to choose from. Then for the third song, they have 6 left.\n",
    "\n",
    " $ \\text{# Jackson k-permutations} = 8*7*6 = 336$\n",
    " \n",
    " formalizing this, the question is how many ways we can select $k$ elements out of a pool of $n$ objects. The answer is \n",
    "\n",
    "$n*(n-1)*...*(n-k+1)$ or in other words, $P_{k}^{n}= \\dfrac{n!}{(n-k)!}$\n",
    "\n",
    "The idea is here that we only \"care\" about the order of the first $k$ objects. The order of the other $(n-k)$ objects doesn't matter, hence they're left out of the equation.\n",
    "\n",
    "### Permutations with Replacement\n",
    "When talking about setlists, it makes total sense to assume that songs will not be played twice. This is not always how it works though. Let's consider throwing a dice. Imagine a bag with three marbles in it: a green one, a red one, and a blue one. Now we'll draw marbles three times in a row, but each time, we'll write down the marble color and *put it back in the bag* before drawing again.\n",
    "\n",
    "Now the number of possible outcomes is $3 * 3 * 3$.\n",
    "\n",
    "Except for the fact that marbles can be  put back in the bag,\n",
    "\n",
    "Generalizing this to $n$, this means that the number of permutations with replacenent when having $n$ distinct objects is equal to $n^j$ where $j$ is the number of \"draws\".\n",
    "\n",
    "### Permutations with Repetition\n",
    "Let's go back to the example where a teaching assistant has a meeting with 3 female and 3 male students. Here, we have n=6 objects, but unlike the previously discussed topics, there is **repetition** in this case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Factorials, Permutations and Combnations\n",
    "\n",
    "    def factorial(n):\n",
    "        prod = 1\n",
    "        while n >= 1:\n",
    "            prod = prod * n\n",
    "            n = n - 1\n",
    "        return prod\n",
    "        \n",
    "    def permutation(n,k):\n",
    "        permut = factorial(n)/factorial(n-k)\n",
    "        return permut\n",
    "        \n",
    "    def combination(n,k):\n",
    "        combin = factorial(n)/(factorial(n-k)*factorial(k))\n",
    "        return combin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Trial and Binomial Distribution\n",
    "\n",
    "**The Bernoulli experiment is a simple experiment in which we have a binary outcome: 0-1, succes-failure, head-tail, etc.**\n",
    "\n",
    "**The binomial distribution describes the process of performing several (denoted by n ) independent Bernoulli trials.**\n",
    "\n",
    "### Binomial Distribution Function\n",
    "\n",
    "    def binom_distr(n,p,k):\n",
    "        p_k = (factorial(n)/(factorial(k)*factorial(n-k)))*(p**k*(1-p)**(n-k))\n",
    "        return p_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probability \n",
    "\n",
    "**Conditional probability emerges when the outcome a trial may influence the results of the upcoming trials.**\n",
    "\n",
    "* $ P(A \\mid B)=\\dfrac{P(A \\cap B)}{P(B)} $\n",
    "\n",
    "### Theorem 1 - Product Rule\n",
    "\n",
    "The **product rule** was used to derive the conditional probability formula above, but often used as is in situations where the conditional probability is easy to compute, but the probability of intersections of events isn't. \n",
    "\n",
    "The intersection of events $A$ and $B$ can be given by\n",
    "\n",
    "\\begin{align}\n",
    "    P(A \\cap B) = P(B) P(A \\mid B) = P(A) P(B \\mid A)\n",
    "\\end{align}\n",
    "\n",
    "### Theorem 2 - Chain Rule\n",
    "\n",
    "The **chain rule** (also called the **general product rule**) permits the calculation of any member of the joint distribution of a set of random variables using only conditional probabilities. \n",
    "\n",
    "Recall the product rule: \n",
    "\n",
    "$P(A \\cap B) = P(A \\mid B) P(B)$\n",
    "\n",
    "When you extend this for three variables:\n",
    "\n",
    "$P(A\\cap B \\cap C) = P(A\\cap( B \\cap C)) = P(A\\mid B \\cap C) P(B \\cap C) = P(A \\mid B \\cap C) P(B \\mid C) P(C)$\n",
    "\n",
    "And you can keep extending this to $n$ variables:\n",
    "\n",
    "$$P(A_1 \\cap A_2 \\cap \\ldots \\cap A_n) = P(A_1 \\mid A_2 \\cap \\ldots\\cap A_n) P(A_2 \\mid A_3  \\cap \\ldots \\cap \\ A_n) P(A_{n-1}|A_n) P(A_n)$$\n",
    "\n",
    "This idea is known as the **chain rule**.\n",
    "\n",
    "If on the other hand you have disjoint events $C_1, C_2,...,C_m$ such that $C_1\\cup C_2\\cup ··· \\cup  C_m = \\Omega$, the probability of any event can be decomposed as:\n",
    "\n",
    "\\begin{align}\n",
    "P(A) = P(A \\mid C_1)P(C_1) + P(A \\mid C_2)P(C_2) + \\ldots + P(A \\mid C_m)P(C_m)\n",
    "\\end{align}\n",
    "\n",
    "### Theorem 3 - Bayes Theorem\n",
    "\n",
    "The **Bayes theorem**, which is the outcome of this section. Below is the formula that we will dig deeper into , in upcoming lessons.\n",
    "\n",
    "\\begin{align}\n",
    "    P(A|B) = \\frac{P(B|A)P(A)}{P(B)} \\text{-        this follows from Theorem 1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning and the Law of Total Probabilities\n",
    "\n",
    "#### Partitioning a Sample Space\n",
    "\n",
    "the Law of Total Probability can be used to calculate $P(B)$. The law requires that you have a set of disjoint events $A_i$ that collectively \"cover\" the event $B$. Then, instead of calculating $P(B)$ directly, you add up the intersection of $B$ with each of the events $A_i$.\n",
    "\n",
    "The probability of a random event $B$ (orange area) can be written down as:\n",
    "\n",
    "\\begin{align}\n",
    "    P(B) &= P(B \\cap A_1) + P(B \\cap A_2) + P(B \\cap A_3)+ P(B \\cap A_4) \\\\\n",
    "         &= P(B \\mid A_1)P(A_1) + P(B \\mid A_2)P(A_2) +P(B \\mid A_3)P(A_3)+ P(B \\mid A_4)P(A_4)\n",
    "\\end{align}\n",
    "\n",
    "#### Law of Total Probability \n",
    "\n",
    "If B1,B2,B3,⋯ is a partition of the sample space S, then for any event A we have\n",
    "\n",
    "$$P(A)= \\sum_i P(A \\cap B_i)= \\sum_i P(A \\mid B_i)P(B_i)$$\n",
    "\n",
    "#### More on Partitions\n",
    "\n",
    "* The natural numbers $\\mathbb{N}$ can be partitioned into even and odd numbers. \n",
    "* The set of animal species in the world can be partitioned into subsets where a subset reflects a continent and each species is positioned in a subset depending on which continent they originated from. \n",
    "\n",
    "In statistics choosing the right partitioning is key as bad choices of partitions may results in many, even more difficult to solve sub-problems.\n",
    "\n",
    "The probability of $A$ can be written as sums of event $B$ (note that $B^c$ is another way of writing $B'$) The total probability rule is:\n",
    "\n",
    "$P(A) = P(A \\cap B) + P(A \\cap B^c)$\n",
    "\n",
    "An alternate version of the total probability rule (found with the multiplication rule) can be used when the necessary probabilities are known  :\n",
    "\n",
    "$P(A \\cap B) = P(A \\mid B)  P(B) + P(A \\cap B^c) = P(A \\mid B^c)P(B^c)$\n",
    "\n",
    "#### Example\n",
    "\n",
    "In a certain county, $60\\%$ of registered voters are Republicans, $30\\%$ are Democrats and $10\\%$ are Independents.\n",
    "\n",
    "When those voters were asked about increasing military spending\n",
    "* $40\\%$ of Republicans opposed it\n",
    "* $65\\%$ of the Democrats opposed it\n",
    "* $55\\%$ of the Independents opposed it.\n",
    "\n",
    "What is the probability that a randomly selected voter in this county opposes increased military spending?\n",
    "\n",
    "You know that:\n",
    "\n",
    "* $\\Omega$ = {registered voters in the county}\n",
    "* $R$ = {registered republicans}, $P(R)$ = 0.6\n",
    "* $D$ = {registered democrats}, $P(D)$ = 0.3\n",
    "* $I$= {registered independents}, $P(I)$ = 0.1\n",
    "* $B$ = {registered voters opposing increased military spending}\n",
    "\n",
    "You also know that:\n",
    "\n",
    "* $P(B \\mid R) = 0.4 $\n",
    "* $P(B \\mid D) = 0.65$\n",
    "* $P(B \\mid I) = 0.55$\n",
    "\n",
    "By the total probability theorem:\n",
    "\n",
    "$Pr(B) = Pr(B \\mid R) Pr(R) + Pr(B \\mid D) Pr(D) + Pr(B \\mid I) Pr(I)$\n",
    "\n",
    "$= (0.4 * 0.6) + (0.65 * 0.3) + (0.55 * 0.1) = 0.49 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Probability Exercise with Function\n",
    "\n",
    "#### More Marbles\n",
    "Bag 1 contains 6 white marbles, 4 black marbles, and 5 gray marbles. Bag 2 contains 3 white marbles, 7 black marbles, and 5 gray marbles.\n",
    "\n",
    "The probability of grabbing the first bag from the box is TWICE the probability of grabbing the second bag.\n",
    "\n",
    "What is the probability of drawing a gray marble from the bag according to law of total probabilities?\n",
    "\n",
    "    import numpy as np\n",
    "    bag1 = {'marbles' : np.array([\"black\", \"white\", \"gray\"]), 'probs' : np.array([4/15, 6/15, 5/15])}\n",
    "    bag2 = {'marbles' : np.array([\"black\", \"white\", \"gray\"]), 'probs' : np.array([7/15, 3/15, 5/15])}\n",
    "    box  = {'bags' : np.array([bag1, bag2]), 'probs' : np.array([2/3, 1/3])}\n",
    "\n",
    "    def sample_marble(box):\n",
    "        # randomly choose a bag \n",
    "        bag = np.random.choice(box['bags'], p = box['probs'])\n",
    "        # randomly choose a marble \n",
    "        return np.random.choice(bag['marbles'], p = bag['probs'])\n",
    "\n",
    "    def probability_of_color(color, box, num_samples=1000):\n",
    "        # get a bunch of marbles \n",
    "        marbles = np.array([sample_marble(box) for ii in range(num_samples)])\n",
    "        # compute fraction of marbles of desired color \n",
    "        return np.sum(marbles == color) / num_samples\n",
    "        \n",
    "    probability_of_color(\"gray\", box, num_samples=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem\n",
    "\n",
    "## $P(A|B) = \\dfrac{P(B|A)P(A)}{P(B)}$\n",
    "\n",
    "## Breaking the Formula Apart\n",
    "\n",
    "Bayes' theorem is quite intuitive, decomposing the conditional probability of 'A given B' in terms of the probability that both events are true divided by the probability that B is true. Bayes theorem takes this natural idea a step further, expressing the probability that both events are true as a conditional probability multiplied by the condition itself.\n",
    "\n",
    "To recap, \n",
    "\n",
    "Bayes' Theorem takes the definition of the conditional likelihood:\n",
    "\n",
    "### $P(A|B) = \\dfrac{P(A \\cap B)}{P(B)}$\n",
    "\n",
    "and rewrites the $P(A \\cap B)$ as $P(B|A)P(A)$, which makes perfect sense; the probability of B given A is true, multiplied by the probability that A is true, gives us the probability that both are true.\n",
    "\n",
    "Making this substitution, you have Bayes' Theorem:\n",
    "\n",
    "### $P(A|B) = \\dfrac{P(B|A)P(A)}{P(B)}$\n",
    "\n",
    "#### A NLP Example\n",
    "\n",
    "A common introductory example to natural language processing or classification is spam. While you may enjoy spam in a can, you probably don't enjoy getting spam in your inbox. Bayes' theorem can serve as a natural classification method in these scenarios. Assume that the word \"offer\" (as in Special Offer, We Have an Offer for You, or Don't Miss This Offer!) occurs in 73% of the spam messages you receive. In comparison, only 10% of your desired mail contains the word \"offer\". If 20% of the messages you receive are spam, and you receive another message with the word \"offer\", what is the probability that it is spam?\n",
    "\n",
    "First, set up the problem:\n",
    "\n",
    "$P(\\text{Spam | Offer}) = \\dfrac{P(\\text{Offer | Spam})P(\\text{Spam})}{P(\\text{Offer})}$\n",
    "\n",
    "Then substituting some of the immediate knowledge we have from the scenario:\n",
    "\n",
    "$P(\\text{Spam | Offer}) = \\dfrac{.73 \\cdot .20}{P(\\text{Offer})}$  \n",
    "\n",
    "Finally, the probability of receiving an email with the word \"offer\", P(Offer), can be evaluated by decomposing it into the two subsets spam and not spam:\n",
    "\n",
    "$P(\\text{Offer}) = P(\\text{Spam})\\cdot P(\\text{Offer | Spam}) + P(\\text{~Spam)} \\cdot P(\\text{Offer | ~Spam})$  \n",
    "$P(\\text{Offer}) = .20 \\cdot .73 + .8 \\cdot .10$  \n",
    "$P(\\text{Offer}) = .146 + .08$  \n",
    "$P(\\text{Offer}) = .226$  \n",
    "\n",
    "Finally, substituting this into the original Bayes formula you have:\n",
    "\n",
    "$P(\\text{Spam | Offer}) = \\dfrac{.73 \\cdot .20}{P(\\text{Offer})}$  \n",
    "$P(\\text{Spam | Offer}) = \\dfrac{.73 \\cdot .20}{.226}$  \n",
    "$P(\\text{Spam | Offer}) = .646$  \n",
    "\n",
    "As you can see, while spam has a much higher occurrence of the word \"offer\", the prescence of the word alone does not provide strong confidence that the message is spam. To provide more statistical power, you will eventually extend Bayes' Theorem to multiple observations simultaneously using the relative probabilities of multiple words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monty Hall Problem\n",
    "\n",
    "To do this, generate a random integer between one and three to represent the door hiding the car. Then, generate a second integer between one and three representing the player's selection. Then, of those the contestant did not choose, select a door concealing a goat to reveal. Record the results of the simulated game if they changed versus if they did not. Repeat this process a thousand (or more) times. Finally, plot the results of your simulation as a line graph. The x-axis should be the number of simulations, and the y-axis should be the probability of winning. (There should be two lines on the graph, one for switching doors, and the other for keeping the original selection.)\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "    stay = []\n",
    "    switch = []\n",
    "    for i in range(10**4):\n",
    "        car_door = np.random.randint(1,4)\n",
    "        contestant_selection = np.random.randint(1,4)\n",
    "        remaining_goats = [door for door in [1,2,3] if door!=car_door and door !=contestant_selection]\n",
    "        door_revealed = np.random.choice(remaining_goats)\n",
    "        if_switch = [door for door in [1,2,3] if door != contestant_selection and door != door_revealed][0]\n",
    "        #Record results if contestant changes door selection\n",
    "        if if_switch == car_door:\n",
    "            switch.append(1)\n",
    "        else:\n",
    "            switch.append(0)\n",
    "        #Record results if contestant keep door selection\n",
    "        if contestant_selection == car_door:\n",
    "            stay.append(1)\n",
    "        else:\n",
    "            stay.append(0)\n",
    "    #Plot the results\n",
    "    plt.plot(range(1,10**4+1), [np.mean(stay[:i]) for i in range(1,10**4+1)], label='Keep Selected Door')\n",
    "    plt.plot(range(1,10**4+1), [np.mean(switch[:i]) for i in range(1,10**4+1)], label='Switch Selected Door')\n",
    "    plt.ylabel('Probability of Winning')\n",
    "    plt.xlabel('Number of Simulations')\n",
    "    plt.title('Simulated Probability of Winning the Monty Hall Game')\n",
    "    plt.legend()\n",
    "    print('Simulated Probabilities:')\n",
    "    print('Chance of Winning Keeping Selected Door: ', np.mean(stay))\n",
    "    print('Chance of Winning Switching Selected Door: ', np.mean(switch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
