{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load necessary libraries\n",
    "    \n",
    "    #importing the libraries\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The Breast Cancer dataset, first obtained from Dr. William H. Wolberg at the University of\n",
    "Wisconsin Hospitals, Madison, is composed of 30 continuous variables and 569 observations. The\n",
    "dataset is based on ten original features describing cancerous cell nuclei derived from a digitized image\n",
    "of a fine needle aspirate of a breast mass. For each of these ten features, the mean, standard error and\n",
    "the ’worst’ value (defined as the mean of the three largest values) have been calculated, resulting in a\n",
    "total of 30 continuous features. The original variable \"area\", for example, has been split into three separate\n",
    "features, area_mean, area_SE and area_worst. The dataset reported only these derived features, not\n",
    "the original variables. The response variable is a categorical variable indicating whether the tumour is\n",
    "malignant (M) or benign (B). The dataset contains 357 benign and 212 malignant examples. The distribution of\n",
    "all variables with respect to response variable is shown as violin plot below. \n",
    "![](VIOLIN.PNG)\n",
    "\n",
    "Further details of dataset can be viewed at [UCI machine learning repo](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names) . We have downloaded this for you as a CSV file: `data.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Import data.csv as Pandas Dataframe. Split the dataset to create X (all features) and Y (Target variable)¶\n",
    "\n",
    "#importing the dataset \n",
    "dataset = pd.read_csv('data.csv')\n",
    "print(\"Cancer data set dimensions : {}\".format(dataset.shape))\n",
    "print(dataset.head())\n",
    "X = dataset.iloc[:, 2:-1].values\n",
    "Y = dataset.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find the dimensions of the data set using the panda dataset ‘shape’ attribute.¶\n",
    "\n",
    "print(\"Cancer data set shape : {}\".format(dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identify \"Malignant\" and \"Benign\" cases in the dataset¶\n",
    "\n",
    "print(dataset.groupby('diagnosis').size())\n",
    "diagnosis\n",
    "\n",
    "### Visualize the dataset, showing distributions of all features with respect to both target classes\n",
    "\n",
    "#Visualization of data\n",
    "dataset.groupby('diagnosis').hist(figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encode \"Malignant\" and \"Benign\" in Y to 0/1¶\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_Y = LabelEncoder()\n",
    "Y = labelencoder_Y.fit_transform(Y)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perform an 80/20 train/test split to X and Y arrays¶\n",
    "\n",
    "#Split the dataset into the Training set and Test set for X and Y \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply StandardScalar() to all features in X_train and X-test\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fit the Naive Bayes Classifier¶\n",
    "\n",
    "#Fitting Naive_Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train_scaled, Y_train);\n",
    "classifier.class_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make predictions from trained classifier¶\n",
    "\n",
    "#Make Predictions\n",
    "Y_pred = classifier.predict(X_test_scaled)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate accuracy using scikit learn\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
