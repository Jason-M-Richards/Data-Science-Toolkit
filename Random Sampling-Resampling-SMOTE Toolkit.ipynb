{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Samples\n",
    "\n",
    "### Make blobs\n",
    "\n",
    "    from sklearn.datasets.samples_generator import make_blobs\n",
    "    X, y = make_blobs(n_samples=100, centers=3, n_features=2)\n",
    "\n",
    "\n",
    "### make moons\n",
    "This function is used for binary classification problems with two classes and generates moon shaped patterns. This function allows you to create dataset and specify the level of noise in the data. That helps you make the dataset more complex if required to test the robustness of an algorithm . This is how you import this function from sklearn :\n",
    "\n",
    "    from sklearn.datasets import make_moons\n",
    "    X, y = make_moons(n_samples=100, noise=0.1)\n",
    "\n",
    "### make circles\n",
    "This function further complicates the generated data and creates values in form of concentric circles. It also features a noise parameter , similar to make_moons(). Below is how you import this function.\n",
    "\n",
    "    from sklearn.datasets import make_circles\n",
    "    X, y = make_circles(n_samples=100, noise=0.05)\n",
    "\n",
    "### make regression\n",
    "This function allows you to create datasets which can be used to test regression algorithms for linear regression. Regression can be performed with a number of algorithms ranging from least squares to more advanced deep networks. We can create datasets by setting number of samples, number of input features, level of noise, and much more. Here is how we import this function:\n",
    "\n",
    "    from sklearn.datasets import make_regression\n",
    "    X, y = make_regression(n_samples=100, n_features=1, noise=0.1)\n",
    "\n",
    "### other datasets and random sample functions\n",
    "https://scikit-learn.org/stable/datasets/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling Methods\n",
    "\n",
    "### Bootstrapping\n",
    "The bootstrap method works by taking random samples with replacement.\n",
    "\n",
    "    def bootstrap(sample, n):\n",
    "        return np.random.choice(sample, size=len(sample), replace=True)\n",
    "\n",
    "### Jacknife\n",
    "The jacknife works by taking samples by removing on, or more, observations at a time\n",
    "\n",
    "    def jack1(sample):\n",
    "        \"\"\"This function should take in a list of n observations and return n lists\n",
    "        each with one member (presumably the nth) removed.\"\"\"\n",
    "        samples = []\n",
    "        for i in range(len(sample)):\n",
    "            new_sample = sample[:i] + sample[i+1:]\n",
    "            samples.append(new_sample)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Sample Mean and Create New Set of Sample Means\n",
    " \n",
    "    def get_sample(data, n): \n",
    "    ''' collects an 'n' number of random samples from a dataset '''\n",
    "        sample = []\n",
    "        while len(sample) != n:\n",
    "            x = np.random.choice(data)\n",
    "            sample.append(x)\n",
    "\n",
    "        return sample\n",
    "\n",
    "    def create_sample_distribution(data, dist_size=100, n=30):\n",
    "    ''' creates a distribution of means from above created samples'''\n",
    "        sample_dist = []\n",
    "        while len(sample_dist) != dist_size:\n",
    "            sample = get_sample(data, n)\n",
    "            sample_mean = sum(sample) / len(sample)\n",
    "            sample_dist.append(sample_mean)\n",
    "\n",
    "        return sample_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    "#### for imbalanced data to resample the minority data\n",
    "\n",
    "    from imblearn.over_sampling import SMOTE, ADASYN\n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SMOTE.html\n",
    "   \n",
    "       X_train_resampled, y_train_resampled = SMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5, n_jobs=1, ratio=None).fit_sample(X_train, y_train)\n",
    "    print(pd.Series(y_train_resampled).value_counts()) #Preview synthetic sample class distribution\n",
    "    \n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "   \n",
    "https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.BorderlineSMOTE.html#imblearn.over_sampling.BorderlineSMOTE\n",
    "   \n",
    "     X_train_resampled, y_train_resampled = BorderlineSMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5, n_jobs=1, m_neighbors=10, kind='borderline-1').fit_sample(X_train, y_train)\n",
    "     \n",
    "     from imblearn.over_sampling import SVMSMOTE\n",
    "     \n",
    " https://imbalanced-learn.readthedocs.io/en/stable/generated/imblearn.over_sampling.SVMSMOTE.html#imblearn.over_sampling.SVMSMOTE\n",
    " \n",
    "     X_train_resampled, y_train_resampled = SVMSMOTE(sampling_strategy='auto', random_state=None, k_neighbors=5, n_jobs=1, m_neighbors=10, svm_estimator=None, out_step=0.5).fit_sample(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
