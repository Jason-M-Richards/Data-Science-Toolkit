{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib\n",
    "\n",
    "Cheat Sheet: https://datacamp-community-prod.s3.amazonaws.com/28b8210c-60cc-4f13-b0b4-5b4f2ad4790b\n",
    "\n",
    "Documentation: https://matplotlib.org/\n",
    "\n",
    "### Stem and Leaf Plot - Matplotlib\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    stems = []\n",
    "    leafs = []\n",
    "\n",
    "    for mark in marks:\n",
    "        stem = mark //10\n",
    "        leaf = mark %10\n",
    "        stems.append(stem)\n",
    "        leafs.append(leaf)\n",
    "        \n",
    "    # Create a stem and leaf plot including the above styling\n",
    "    plt.figure(figsize=(12,8))\n",
    "    #markerline, stemlines, baseline = \n",
    "\n",
    "    plt.stem(stems, leafs, '-.', 'o' )\n",
    "    plt.title('Stem and Leaf Plot for Student Marks', fontsize = 30 )\n",
    "    plt.ylabel('Leafs', fontsize = 20)\n",
    "    plt.xlabel('Stems', fontsize = 20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "### Keras Training/Validation Loss and Accuracy Plots - Matplotlib\n",
    "\n",
    "    # loss visualization\n",
    "    import matplotlib.pyplot as plt\n",
    "    loss_values = model_val_dict['loss']\n",
    "    val_loss_values = model_val_dict['val_loss']\n",
    "\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    plt.plot(epochs, loss_values, 'g', label='Training loss')\n",
    "    plt.plot(epochs, val_loss_values, 'blue', label='Validation loss')\n",
    "\n",
    "    plt.title('Training & validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    #accuracy visualization\n",
    "    acc_values = model_val_dict['acc'] \n",
    "    val_acc_values = model_val_dict['val_acc']\n",
    "\n",
    "    plt.plot(epochs, acc_values, 'r', label='Training acc')\n",
    "    plt.plot(epochs, val_acc_values, 'blue', label='Validation acc')\n",
    "    plt.title('Training & validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "### Matplotlib Images\n",
    "\n",
    "#### Intermedaite Activations in CNN\n",
    "\n",
    "**A model must already be saved in order for this visualization to be used**\n",
    "\n",
    "    #load saved model\n",
    "    from keras.models import load_model\n",
    "    model = load_model('chest_xray_all_with_augmentation_data.h5')\n",
    "    model.summary()\n",
    "    \n",
    "    #load an image\n",
    "    from keras.preprocessing import image\n",
    "    import matplotlib.image as mpimg\n",
    "    import matplotlib.pyplot as plt\n",
    "    %matplotlib inline\n",
    "\n",
    "    filename = 'person3_virus_16.jpeg'\n",
    "    img = image.load_img(filename, target_size=(150, 150))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "    #transform to tensor and visualize\n",
    "    import numpy as np\n",
    "\n",
    "    img_tensor = image.img_to_array(img)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "    #Follow the Original Model Preprocessing\n",
    "    img_tensor /= 255.\n",
    "\n",
    "    #Check tensor shape\n",
    "    print(img_tensor.shape)\n",
    "\n",
    "    #Preview an image\n",
    "    plt.imshow(img_tensor[0])\n",
    "    plt.show()\n",
    "    \n",
    "    #plot features map\n",
    "    from keras import models\n",
    "    import math #used for determining the number of rows in our figure below\n",
    "\n",
    "    # Extract model layer outputs\n",
    "    layer_outputs = [layer.output for layer in model.layers[:8]]\n",
    "\n",
    "    # Create a model for displaying the feature maps\n",
    "    activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n",
    "    activations = activation_model.predict(img_tensor)\n",
    "\n",
    "    #Extract Layer Names for Labelling\n",
    "    layer_names = []\n",
    "    for layer in model.layers[:8]:\n",
    "        layer_names.append(layer.name)\n",
    "\n",
    "    total_features = sum([a.shape[-1] for a in activations])\n",
    "    total_features\n",
    "\n",
    "    n_cols = 16\n",
    "    n_rows = math.ceil(total_features / n_columns)\n",
    "\n",
    "\n",
    "    iteration = 0\n",
    "    fig , axes = plt.subplots(nrows=n_rows, ncols=n_columns, figsize=(n_cols, n_rows*1.5))\n",
    "\n",
    "    for layer_n, layer_activation in enumerate(activations):\n",
    "        n_channels = layer_activation.shape[-1]\n",
    "        for ch_idx in range(n_channels):\n",
    "            row = iteration // n_columns\n",
    "            column = iteration % n_columns\n",
    "\n",
    "            ax = axes[row, column]\n",
    "\n",
    "            channel_image = layer_activation[0,\n",
    "                                             :, :,\n",
    "                                             ch_idx]\n",
    "            # Post-process the feature to make it visually palatable\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= channel_image.std()\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "\n",
    "            ax.imshow(channel_image, aspect='auto', cmap='viridis')\n",
    "            ax.get_xaxis().set_ticks([])\n",
    "            ax.get_yaxis().set_ticks([])\n",
    "\n",
    "            if ch_idx == 0:\n",
    "                ax.set_title(layer_names[layer_n], fontsize=10)\n",
    "            iteration += 1\n",
    "\n",
    "    fig.subplots_adjust(hspace=1.25)\n",
    "    plt.savefig(\"Intermediate_Activations_Visualized.pdf\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    #Add Normalization Option\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seaborn\n",
    "\n",
    "Cheat Sheet:  https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python_Seaborn_Cheat_Sheet.pdf\n",
    "\n",
    "Documentation: https://seaborn.pydata.org/\n",
    "\n",
    "**not on cheatsheet**\n",
    "- two types of objects (FacetGrid, AxesSubplot)\n",
    "- relplot and catplot are FacetGrids\n",
    "- check which object by setting the visual to a variable (g=sns.catplot())\n",
    "- check type with type(g)\n",
    "- add Title with g.fig.suptitle('Title') for FacetGrid\n",
    "- add Title with g.set_title for AxesSubplot\n",
    "\n",
    "### Relplot\n",
    "> Creates a relational plot that can contain several variables with unique customization\n",
    "\n",
    "    sns. relplot(x=x , y=y , data=data, kind=['scatter', 'line'], hue='separates colors into this variable', style='sets different point styles to this variable', aplha=.1-1.0, size='sets size of points based on count, setting to 'size' will vary the size by count', col='creates column style subplots based on varaibles', row='creates row style subplots based on variable, col_order='set col order [list], row_order=, set row order [list]\n",
    "    \n",
    "### Catplot\n",
    "\n",
    "> Same usecase as relplot, only for categorical data. Differences are:\n",
    "- kind='count','bar','box', 'point'\n",
    "- sym='changes style or use of outliers on boxplots'\n",
    "- ci=None (removes ci marks from barchart)\n",
    "- whis='can adjust range of whiskers in boxplot'\n",
    "- order='similar to col_order and row_order'\n",
    "- join= 'if set to False, will remove joining line in point plot'\n",
    "- estimator= 'can change the estimation from mean to a numpy estimator (median, std, etc.)'\n",
    "- capsize= 'places an upper and lower cap on the confidence interval lines with a set length'\n",
    "\n",
    "### Highlighting Specific Reference Points (scatterplot)\n",
    "\n",
    "    houston_pollution = pollution[pollution.city  ==  'Houston'].copy()\n",
    "\n",
    "    # Find the highest observed O3 value\n",
    "    max_O3 = houston_pollution.O3.max()\n",
    "\n",
    "    # Make a column that denotes which day had highest O3\n",
    "    houston_pollution['point type'] = ['Highest O3 Day' if O3  ==  max_O3 else 'Others' for O3 in houston_pollution.O3]\n",
    "\n",
    "    # Encode the hue of the points with the O3 generated column\n",
    "    sns.scatterplot(x = 'NO2',\n",
    "                    y = 'SO2',\n",
    "                    hue = 'point type',\n",
    "                    data = houston_pollution)\n",
    "    plt.show()\n",
    "    \n",
    "### KDE comparing one vs rest groups\n",
    "\n",
    "    sns.distplot(pollution[pollution.city == 'Vandenberg Air Force Base'].O3, \n",
    "                 label = 'Vandenberg', \n",
    "                 # Turn of the histogram and color blue to stand out\n",
    "                 hist = False,\n",
    "                 color = 'steelblue', \n",
    "                 # Turn on rugplot\n",
    "                 rug = True)\n",
    "\n",
    "    sns.distplot(pollution[pollution.city != 'Vandenberg Air Force Base'].O3, \n",
    "                 label = 'Other cities',\n",
    "                 # Turn off histogram and color gray\n",
    "                 hist = False,  \n",
    "                 color = 'gray')\n",
    "    plt.show()\n",
    "    \n",
    "### Beeswarm Plot for comparing multiple classes in one time period\n",
    "\n",
    "    # Filter data to just March\n",
    "    pollution_mar = pollution[pollution.month == 3]\n",
    "\n",
    "    # Plot beeswarm with x as O3\n",
    "    sns.swarmplot(y = \"city\",\n",
    "                  x = 'O3', \n",
    "                  data = pollution_mar, \n",
    "                  # Decrease the size of the points to avoid crowding \n",
    "                  size = 3)\n",
    "\n",
    "    # Give a descriptive title\n",
    "    plt.title('March Ozone levels by city')\n",
    "    plt.show()\n",
    "    \n",
    "### Annotate Plots with arrow and custom text placement\n",
    "\n",
    "    # Query and filter to New Years in Long Beach\n",
    "    jan_pollution = pollution.query(\"(month  ==  1) & (year  ==  2012)\")\n",
    "    lb_newyears = jan_pollution.query(\"(day  ==  1) & (city  ==  'Long Beach')\")\n",
    "\n",
    "    sns.scatterplot(x = 'CO', y = 'NO2',\n",
    "                    data = jan_pollution)\n",
    "\n",
    "    # Point arrow to lb_newyears & place text in lower left \n",
    "    plt.annotate('Long Beach New Years',\n",
    "                 xy = (lb_newyears.CO, lb_newyears.NO2),\n",
    "                 xytext = (2, 15), \n",
    "                 # Shrink the arrow to avoid occlusion\n",
    "                 arrowprops = {'facecolor':'gray', 'width': 3, 'shrink': 0.03},\n",
    "                 backgroundcolor = 'white')\n",
    "    plt.show()\n",
    "    \n",
    "### Bootstrap Histogram Confidence\n",
    "\n",
    "    cinci_may_NO2 = pollution.query(\"city  ==  'Cincinnati' & month  ==  5\").NO2\n",
    "\n",
    "    # Generate bootstrap samples\n",
    "    boot_means = bootstrap(cinci_may_NO2, 1000)\n",
    "\n",
    "    # Get lower and upper 95% interval bounds\n",
    "    lower, upper = np.percentile(boot_means, [2.5, 97.5])\n",
    "\n",
    "    # Plot shaded area for interval\n",
    "    plt.axvspan(lower, upper, color = 'gray', alpha = 0.2)\n",
    "\n",
    "    # Draw histogram of bootstrap samples\n",
    "    sns.distplot(boot_means, bins = 100, kde = False)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "### Swarmplot Bootstrap\n",
    "\n",
    "    # Initialize a holder DataFrame for bootstrap results\n",
    "    city_boots = pd.DataFrame()\n",
    "\n",
    "    for city in ['Cincinnati', 'Des Moines', 'Indianapolis', 'Houston']:\n",
    "        # Filter to city\n",
    "        city_NO2 = pollution_may[pollution_may.city  ==  city].NO2\n",
    "        # Bootstrap city data & put in DataFrame\n",
    "        cur_boot = pd.DataFrame({'NO2_avg': bootstrap(city_NO2, 100), 'city': city})\n",
    "        # Append to other city's bootstraps\n",
    "        city_boots = pd.concat([city_boots,cur_boot])\n",
    "\n",
    "    # Beeswarm plot of averages with citys on y axis\n",
    "    sns.swarmplot(y = \"city\", x = \"NO2_avg\", data = city_boots, color = 'coral')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folium Interactive Maps\n",
    "\n",
    "https://python-visualization.github.io/folium/\n",
    "    \n",
    "    import folium\n",
    "\n",
    "    lat = 51.51\n",
    "    long = -0.14\n",
    "\n",
    "    #Create a map of the area\n",
    "    base_map = folium.Map([lat, long], zoom_start=13)\n",
    "    base_map\n",
    "    \n",
    "    import numpy as np\n",
    "\n",
    "    #Generate some random locations to add to our map\n",
    "    x = [lat + np.random.uniform(-.1,.1) for i in range(20)]\n",
    "    y = [long + np.random.uniform(-.1,.1) for i in range(20)]\n",
    "    points = list(zip(x, y))\n",
    "    for p in points:\n",
    "        lat = p[0]\n",
    "        long = p[1]\n",
    "        marker = folium.Marker(location=[lat, long])\n",
    "        marker.add_to(base_map)\n",
    "    base_map\n",
    "    \n",
    "    #adding popup boxes to location points\n",
    "    for p in points:\n",
    "        lat = p[0]\n",
    "        long = p[1]\n",
    "        popup_text = \"Lattitude: {}, Longitude: {}\".format(lat,long)\n",
    "        popup = folium.Popup(popup_text, parse_html=True)\n",
    "        marker = folium.Marker(location=[lat, long], popup=popup)\n",
    "        marker.add_to(base_map)\n",
    "    base_map\n",
    "    \n",
    "### Converting geodataframe data to folium points for plotting    \n",
    "    \n",
    "    # Print the head of the urban_polygon\n",
    "    print(urban_polygon.head())\n",
    "\n",
    "    # Create urban_center from the urban_polygon center\n",
    "    urban_center = urban_polygon.center[0]\n",
    "\n",
    "    # Print urban_center\n",
    "    print(urban_center)\n",
    "\n",
    "    # Create array for folium called urban_location (switching from lng,lat to lat, lng)\n",
    "    urban_location = [urban_center.y, urban_center.x]\n",
    "\n",
    "    # Print urban_location\n",
    "    print(urban_location)\n",
    "    \n",
    "    # Create array for called folium_loc from the urban_polygon center point\n",
    "    point = urban_polygon.center[0]\n",
    "    folium_loc = [point.y, point.x]\n",
    "\n",
    "    # Construct a map from folium_loc: downtown_map\n",
    "    downtown_map = folium.Map(location = folium_loc, zoom_start = 15)\n",
    "\n",
    "    # Draw our neighborhood: Urban Residents\n",
    "    folium.GeoJson(urban_polygon.geometry).add_to(downtown_map)\n",
    "\n",
    "    # Display the map\n",
    "    display(downtown_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choropleth\n",
    "\n",
    "### Folium \n",
    "\n",
    "**arguments**\n",
    "- geo_data - the source data for the polygons (geojson file or a GeoDataFrame)\n",
    "- name - the name of the geometry column (or geojson property) for the polygons\n",
    "- data- the source DataFrame or Series for the normalized data\n",
    "- columns- a list of columns: one that corresponds to the polygons and one that has the value to plot\n",
    "- key_on - a GeoJSON variable to bind the data to (always starts with feature)\n",
    "- fill_color - polygon fill color (defaults to blue)\n",
    "- fill_opacity - range between 0 (transparent) and 1 (completely opaque)\n",
    "- line_color - color of polygon border lines (defaults to black)\n",
    "- line_opacity - range between 0 (transparent) and 1 (completely opaque)\n",
    "- legend_name - creates a title for the legend\n",
    "\n",
    "#### Folium Choropleth with Markers and Popups\n",
    "\n",
    "    # Center point for Nashville\n",
    "    nashville = [36.1636,-86.7823]\n",
    "\n",
    "    # Create map\n",
    "    m = folium.Map(location=nashville, zoom_start=10)\n",
    "    \n",
    "    # Build choropleth\n",
    "    m.choropleth(\n",
    "        geo_data=districts_and_permits,\n",
    "        name='geometry',\n",
    "        data=districts_and_permits,\n",
    "        columns=['district', 'permit_density'],\n",
    "        key_on='feature.properties.district',\n",
    "        fill_color='Reds',\n",
    "        fill_opacity=0.5,\n",
    "        line_opacity=1.0,\n",
    "        legend_name='2017 Permitted Building Projects per km squared')\n",
    "        \n",
    "        # Create LayerControl and add it to the map            \n",
    "    folium.LayerControl().add_to(m)\n",
    "\n",
    "    # Display the map\n",
    "    display(m)\n",
    "    \n",
    "    # Create center column for the centroid of each district\n",
    "    districts_and_permits['center'] = districts_and_permits.geometry.centroid\n",
    "\n",
    "    # Build markers and popups\n",
    "    for row in districts_and_permits.iterrows():\n",
    "        row_values = row[1] \n",
    "        center_point = row_values['center']\n",
    "        location = [center_point.y, center_point.x]\n",
    "        popup = ('Council District: ' + str(row_values['district']) + \n",
    "                 ';  ' + 'permits issued: ' + str(row_values['bldg_permits']))\n",
    "        marker = folium.Marker(location = location, popup = popup)\n",
    "        marker.add_to(m)\n",
    "\n",
    "\n",
    "\n",
    "     #Display the map\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
