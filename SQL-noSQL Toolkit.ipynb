{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Cheat Sheet\n",
    "http://www.sqltutorial.org/wp-content/uploads/2016/04/SQL-cheat-sheet.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLite3\n",
    "\n",
    "### Working with SQLite3 DBs in Jupyter Notebook\n",
    "\n",
    "    #First we import the sqlite3 module\n",
    "    ```python\n",
    "    #import sqlite3\n",
    "    ```\n",
    "\n",
    "    #Next we create our connection to the sqlite database file `pet_database.db` by using the method `.connect()` and the file name we would like for our database.\n",
    "    ```python\n",
    "    connection = sqlite3.connect('pet_database.db')\n",
    "    ```\n",
    "\n",
    "    #Then we create the *cursor* which we will use to execute SQL statements\n",
    "    ```python\n",
    "    cursor = connection.cursor()\n",
    "    ```\n",
    "\n",
    "    #Finally, when we want to execute our SQL statements we reference our SQL cursor object and call the method `.execute()` with our SQL statement as the argument\n",
    "    ```python\n",
    "    sql_return = cursor.execute('''SQL statement GOES here;''')\n",
    "    ```\n",
    "    To see a list of the information we retrieved from our SQL statement, we can take our `sql_return` variable and call the method `.fetchall()`, which will return a list of records (if we are executing a `SELECT` statement.\n",
    "    \n",
    "    #creating a table CATS with ID column as primary key using integers, a NAME column using text and an AGE column using integers\n",
    "    cursor.execute('''\n",
    "                CREATE TABLE cats (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                name TEXT, \n",
    "                age INTEGER\n",
    "                );'''\n",
    "               ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "TEXT, INTEGER, REAL(FLOAT), BLOB(BINARY DATA)\n",
    "\n",
    "### Primary and Foreign Keys\n",
    "Primary Key\t\n",
    "- Primary key uniquely identify a record in the table.\t\n",
    "- Primary Key can't accept null values.\t\n",
    "- By default, Primary key is clustered index and data in the database table is physically organized in the sequence of clustered index.\t\n",
    "- We can have only one Primary key in a table.\t\n",
    "    \n",
    "Foreign Key\n",
    "- Foreign key is a field in the table that is primary key in another table.\n",
    "- Foreign key can accept multiple null value.\n",
    "- Foreign key do not automatically create an index, clustered or non-clustered. You can manually create an index on foreign key.\n",
    "- We can have more than one foreign key in a table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using SQL syntax with `pandasql`\n",
    "\n",
    "Since SQL is such a powerful, comfortable tool for Data Scientists, some people had the bright idea of creating a library that lets users query DataFrames using SQL-style syntax.  This library is called [pandasql]( https://pypi.org/project/pandasql/ ).\n",
    "\n",
    "We can install `pandasql` using the bash comman `pip install pandasql`.\n",
    "\n",
    "#### Importing pandasql\n",
    "\n",
    "In order to use `pandasql`, we need to start by importing a `sqldf` object from `pandasql`\n",
    "\n",
    "    ```python\n",
    "    from pandasql import sqldf\n",
    "    ```\n",
    "\n",
    "Next, we'll write a lambda function that will make it quicker and easier to write queries.  Normally, we would have to pass in the global variables every time we use an object.  In order to avoid doing this every time, we'll write a lambda that does this for us. \n",
    "\n",
    "    ```python\n",
    "    pysqldf = lambda q: sqldf(q, globals())\n",
    "    ```\n",
    "\n",
    "Now, when we pass a query into `pysqldf`, the lambda will also pass along the globals for us, saving us that repetitive task. \n",
    "\n",
    "#### Writing Queries\n",
    "\n",
    "To write a query, we just format it as a multi-line string!\n",
    "\n",
    "    ```python\n",
    "    q = \"\"\"SELECT\n",
    "            m.date, m.beef, b.births\n",
    "         FROM\n",
    "            meats m\n",
    "         INNER JOIN\n",
    "            births b\n",
    "               ON m.date = b.date;\"\"\"\n",
    "    ```\n",
    "\n",
    "In order to query DataFrames, we can just pass in the query string we've created to our `sqldf` object that we stored in `pysqldf`.  This will return a DataFrame.  \n",
    "\n",
    "    ```python\n",
    "    results = pysqldf(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization in Databases\n",
    "You've probably noticed by now that tables in databases are essentially just spreadsheets. However, there's a reason that companies spend millions of dollars on building and maintaining performant relational databases, instead of just keeping a massive spreadsheet in Excel. The main advantage that databases provide are a robust way to organize our tables--these organization strategies are referred to as normalization. There are different levels of normalizations, ranging from 0th normal form to 3rd normal form (there are more normalized versions than 3rd normal form, but they're rare enough that you likely won't have to worry about them).\n",
    "\n",
    "#### What is Database Normalization?\n",
    "Database normalization refers to the practice of storing data across one or more tables based on the information that data contains. You might have noticed that although we typically jam everything into a single DataFrame when exploring or modeling our data, things like a customer's name, address, and order history are typically stored in separate tables, and that each of those corresponding tables only contains data pertaining to a specific topic (e.g. all addresses stored in the \"addresses\" table, orders stored in the \"orders\" table, etc). The information is linked to other relevant records by the use of keys.\n",
    "\n",
    "#### Benefits of Database Normalization\n",
    "You've probably wondered at some point--why bother? Storing data in separate tables and then joining with foreign keys when that information is needed can be a bit time consuming. However, Database Normalization provides some great benefits:\n",
    "\n",
    "- 1. Minimize Duplicate Data\n",
    "By storing data in separate tables, we can avoid the need to store duplicate data in our database. Duplicating records is a waste of space, and space used to be quite expensive! By storing a customer's information in a \"Customer\" table, we can just reference the appropriate key for that customer in an \"Orders\" table every time that customer places an order. In a denormalized database to track orders (technically called 0th normal form), every row in the spreadsheet would be an order, and if a customer has placed 20 orders, then you'll have that customer's name, shipping address, and other information repeated across 20 different rows! With a normalized database, we can save on memory by just pointing to that customer in the customer table every time they make an order.\n",
    "\n",
    "- 2. Minimize Data Modification Issues\n",
    "Another benefit of a normalized database is that it makes it much easier to avoid issues that arise from modifying information. Consider the example we used above of a single spreadsheet storing information about orders and the customers that placed them. Let's assume that our customer changes their address. The simplest solution here would be to just put the new address in only on new orders, and leave the old address alone in the old orders. But what happens when you try to query for that customer's address? That query will return two different addresses for that customer, with no obvious way for you to tell which address is current. If we decide to change all instances of that customer's address to match the current one, then that leads to a performance problem--making that one change of address means changing it for every single row in our spreadsheet, would slow down our database.\n",
    "\n",
    "By normalizing a database, we can plan ahead for issues like this. With an \"Address\" table, perhaps we can add datestamps to each address to tell when it is changed, or a column allowing the customer to name the different addresses they ship items to. Best of all, if we decide to change a value, we only need to change it in one place--whether that customer has placed one order or one million, we're only changing a single cell in a single table--no performance hit!\n",
    "\n",
    "- 3. Simplifying Queries\n",
    "This was alluded to in the previous paragraphs, but one of the main benefits of database normalization is that it simplifies the structure of our queries when we need to get information.\n",
    "\n",
    "For instance, let's assume we have a spreadsheet containing information on sales associates in our company. Each row represents a different member of the sales team. Each customer that the associate has dealt with is stored as a different column in the speadsheet under headings such as \"Customer_1\", \"Customer_2\", etc. Some companies have been with us a long time, and have dealt with multiple sales associates. What if we wanted to query our data to get all the sales associates that have ever sold anything to IBM?\n",
    "\n",
    "Our query would be horrible, and would look something like:\n",
    "\n",
    "    SELECT SalesAssociate FROM SalesTeam\n",
    "    WHERE Customer_1 = 'IBM' OR\n",
    "    Customer_2 = 'IBM' OR\n",
    "    Customer_3 = 'IBM' OR... // continues on like this for every customer column :-(\n",
    "\n",
    "This becomes much, much simpler when we use a normalized database. We can just store all of our sales associate data in one table, all of our customer information in another table, and link them together with a join table (since this is a many-to-many relationship). This greatly simplifies our query.\n",
    "\n",
    "#### Types of Normal Forms\n",
    "Although there are more strict types of normalization such as 4th and 5th normal form, in practice, you'll rarely ever run into database stored in versions other than 1st, 2nd, or 3rd normal form. Since you're a data scientist, not a database administrator, you don't need to spend too much time worrying about the differences between the 3--however, you should have a basic understanding of what each means.\n",
    "\n",
    "1st Normal Form: All rows have the same number of columns. No column names are repeated.\n",
    "\n",
    "2nd Normal Form: Meets the specifications of 1st normal form, plus all column data depends on the entire primary key, and not just part (remember, primary keys can be a composite of 2 or more columns in a table!)\n",
    "\n",
    "3rd Normal Form: Meets the specifications of 2nd normal form, plus no column depends on other columns. Each column in the table depends on the primary key, the whole primary key, and nothing but the primary key.\n",
    "\n",
    "*/Often, you'll need to get data out of databases where it is stored in 3rd normal format, and then denormalize the data you need so that it fits in a single DataFrame we can use for all our data science-y purposes./*\n",
    "\n",
    "#### Table Relationships\n",
    "Recall that entities stored in our database tables can be related to one or more entities in other tables. Before we move onto reading Entity-Relationship diagrams in the next lesson, we'll quickly review the different types of relationships, and provide an example of each.\n",
    "\n",
    "##### One-to-One Relationships\n",
    "In one-to-one relationships, an entity in a table is connected to exactly one entity in a corresponding table through a foreign key.\n",
    "\n",
    "Example: Employee and Compensation. Each employee will only have one row in the compensation table related to them.\n",
    "\n",
    "##### One-to-Many Relationships\n",
    "In one-to-many relationships, an entity in a table can be connected to one or more entities in a corresponding table through a foreign key.\n",
    "\n",
    "Example: City to Zip Code. A city can contain multiple zip codes, but each zip code is only in one city.\n",
    "\n",
    "##### Many-to-Many Relationships\n",
    "In many-to-many relationships, an multiple entities in a table can be connected to one or more of the same entities in a corresponding table. These connections are queried through an intermediate table called a Join Table (more on this in a future lesson!)\n",
    "\n",
    "Example: Sales Associates and Customers. In our previous normalization example, each sales associate deals with multiple companies, and each company deals with multiple sales associates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Relationship Diagram\n",
    "\n",
    "https://yintingchou.com/posts/2017-09-01-learning-microsoft-sql-server/ERD.png\n",
    "\n",
    "#### ERD relationship notation\n",
    "\n",
    "https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/ER-diagram-symbols-and-meaning/ERD_notation-416x315.PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQLalchemy and Object Relation Mappers (ORM)\n",
    "\n",
    "#### Defining Our Mappings\n",
    "We'll begin by importing everything we need to create our database and structure our mappings so that they look like the tables in the ERD.\n",
    "\n",
    "    #import packages and decalre a base\n",
    "    from sqlalchemy import *\n",
    "    from sqlalchemy.orm import relationship #to create relationships\n",
    "    from sqlalchemy.ext.declarative import declarative_base #to declare a base\n",
    "    Base = declarative_base()\n",
    "\n",
    "#### Creating Class Mappings\n",
    "\n",
    "https://www.sqlalchemy.org/\n",
    "\n",
    "In order to set up our classes, define:\n",
    "\n",
    "- The __tablename__ for each class\n",
    "- The attributes of each class, which will be Column objects\n",
    "- The relationship that each class has to other classes\n",
    "\n",
    "\n",
    "        #Complete the Customer, ShoppingCart, and Item classes.\n",
    "    \n",
    "        class Customer(Base):\n",
    "            __tablename__ = 'customer'\n",
    "\n",
    "            id = Column(Integer, primary_key=True)\n",
    "            name = Column(String)\n",
    "            cart_id = Column(Integer, ForeignKey('shoppingCart.id'))\n",
    "\n",
    "            # Create 1-to-1 relationship with ShoppingCart, as shown in the SQLAlchemy documentation\n",
    "            shoppingCart = relationship('ShoppingCart', uselist=False, back_populates='customer')\n",
    "        class ShoppingCart(Base):\n",
    "            __tablename__ = \"shoppingCart\"\n",
    "\n",
    "            id = Column(Integer, primary_key=True)\n",
    "            item_id = Column(Integer, ForeignKey('item.id'))\n",
    "            # Create 1-to-1 relationship with Customer\n",
    "            customer = relationship('Customer', uselist=False, back_populates='shoppingCart')\n",
    "            # Create 1-to-many relationship with Item\n",
    "            items = relationship('Item')\n",
    "        class Item(Base):\n",
    "            __tablename__ = 'item'\n",
    "\n",
    "            id = Column(Integer, primary_key=True)\n",
    "            description = Column(String)\n",
    "            price = Column(Float)\n",
    "\n",
    "        #Creating Our Database\n",
    "        engine = create_engine('sqlite:///shopping_cart.db', echo=True)\n",
    "        Base.metadata.create_all(engine)\n",
    "\n",
    "        #create some objects, and then populate the database with them.\n",
    "\n",
    "        customer1 = Customer(name=\"Jane\")\n",
    "        item1 = Item(description=\"widget\", price=9.99)\n",
    "        cart1 = ShoppingCart(customer=customer1, items = item1)\n",
    "        customer1.shoppingCart = cart1\n",
    "        \n",
    "        #add our new data to our database tables by creating a session object.\n",
    "        from sqlalchemy.orm import sessionmaker, Session\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        session = Session()\n",
    "\n",
    "        #add items to our database one at a time by passing them in as a parameter to session.add(). \n",
    "        #add multiple items by passing them as a list into the add_all() method.\n",
    "        session.add_all([customer1, cart1, item1])\n",
    "\n",
    "        #see all the items that have been added by checking the session objectthe cell below.\n",
    "        #session.new\n",
    "\n",
    "\n",
    "        #commit our objects to push them to the database.\n",
    "        session.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying with SQLalchemy\n",
    "\n",
    "    #Connecting to the Database\n",
    "    import sqlalchemy\n",
    "    from sqlalchemy import create_engine\n",
    "    from sqlalchemy.orm import Session, sessionmaker\n",
    "    engine = create_engine(\"sqlite:///Northwind_small.sqlite\", echo=True)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    #Get Table Names and Table Information\n",
    "    from sqlalchemy import inspect\n",
    "    inspector = inspect(engine)\n",
    "    print(inspector.get_table_names())\n",
    "\n",
    "    #function to print out the name and type of each column in a well-formatted way.\n",
    "    def get_columns_info(col_name):\n",
    "        cols_list = inspector.get_columns(col_name)\n",
    "\n",
    "        print(\"Table Name: {}\".format(col_name))\n",
    "        print(\"\")\n",
    "\n",
    "        for column in cols_list:\n",
    "            print(\"Name: {} \\t Type: {}\".format(column['name'], column['type']))\n",
    "    get_columns_info('Employee')\n",
    "\n",
    "    #Connecting and Executing Raw SQL Statements\n",
    "    con = engine.connect()\n",
    "    rs = con.execute(\"SELECT * FROM Customer LIMIT 5\")\n",
    "    print(rs.fetchall())\n",
    "\n",
    "    #Storing data in Pandas DataFrame\n",
    "    import pandas as pd\n",
    "    rs = con.execute(\"SELECT firstname, lastname, title from Employee\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.head()\n",
    "\n",
    "\n",
    "    Nice! We can now read our results. However, the columns of our DataFrame aren't labeled. Luckily, pandas plays nicely with the sqlalchemy library, and can actually execute sql queries!\n",
    "\n",
    "    #query to select all orders from customer VINET\n",
    "    df = pd.read_sql_query(\"SELECT * FROM [Order] WHERE CUSTOMERId = 'VINET'\", engine)\n",
    "    df.head()\n",
    "\n",
    "\n",
    "    #Executing JOIN Statements\n",
    "    df = pd.read_sql_query(\"\"\"SELECT o.ID, c.CompanyName, Count(*) num_orders FROM [Order] \\\n",
    "    o INNER JOIN Customer c on o.CustomerID = c.ID GROUP BY c.CompanyName ORDER BY num_orders DESC\"\"\", engine)\n",
    "    df.head()\n",
    "\n",
    "    #JOINs with Many-To-Many Relationships\n",
    "    q = \"\"\"SELECT LastName, FirstName, COUNT(*) as TerritoriesAssigned from \\\n",
    "    Employee \\\n",
    "    JOIN EmployeeTerritory et on Employee.Id = et.employeeId \\\n",
    "    GROUP BY Employee.lastname \\\n",
    "    ORDER BY TerritoriesAssigned DESC\"\"\"\n",
    "    df2 = pd.read_sql_query(q, engine)\n",
    "    df2.head()\n",
    "\n",
    "    #create mappings of tables to objects in python to use ORM\n",
    "    from sqlalchemy import MetaData\n",
    "    from sqlalchemy.ext.automap import automap_base\n",
    "    metadata = MetaData()\n",
    "    metadata.reflect(engine)\n",
    "    Base = automap_base(metadata=metadata)\n",
    "    Base.prepare()\n",
    "    Employee, Customer = Base.classes.Employee, Base.classes.Customer\n",
    "\n",
    "#### Writing Basic Queries\n",
    "\n",
    "    #for loop that iterates through the results returned by a session.query() of the Employee table and orders the results by the Employee's .HireDate attribute.\n",
    "    for instance in session.query(Employee).order_by(Employee.HireDate):\n",
    "        print(\"Name: {}, {}  Hired: {}\".format(instance.LastName, instance.FirstName, instance.HireDate))\n",
    "\n",
    "    Implicit JOINs using .filter()\n",
    "    One great benefit of using session.query() to query our data is that we can easily execute implicit joins by making use of the .filter() method.\n",
    "\n",
    "    So far we've only explicitly specified mappings for the Employee and Customer classes. We'll need to do this now for the Product and Category classes before we can use them with session.query().\n",
    "\n",
    "    #set the mappings for Product and Category.\n",
    "    Product, Category = Base.classes.Product, Base.classes.Category\n",
    "\n",
    "    #for loop that iterates through all results returned from a query of Products and Categories and use the .filter() method to only include cases where the Product's .CategoryID matches the Category's .Id attribute.\n",
    "    for p, c in session.query(Product, Category).filter(Product.CategoryId==Category.Id).all():\n",
    "        print(\"Product Name: {}  Category Name: {}\".format(p.ProductName, c.CategoryName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoSQL Database Types\n",
    "\n",
    "#### Key - Value DatabasesÂ¶\n",
    "Key value databases, are one of the most simplistic database systems, simply storing data as key-value pairs, just like python dictionaries. The most common implementation is Redis.\n",
    "\n",
    "- Redis\n",
    "- Initial release: 2009\n",
    "\n",
    "Redis has been used by large companies including github and instagram. It is by far the most common key-value database.\n",
    "\n",
    "#### Document Model Databases\n",
    "Document model databases are a subclass of key-value databases. The initial concept is of documents such as json or xml. The database stores these documents using key-value pairs. However, unlike key-value databases, document model databases have the additional ability to access information within these documents directly.\n",
    "\n",
    "- MongoDB\n",
    "- Initial release: 2009\n",
    "\n",
    "MongoDB is one of the most popular sql alternatives. It represents data very similar to the JSON format we have been investigating today. It also supports a distributed model where data can be stored across multiple computers.\n",
    "\n",
    "#### Wide Column Databases\n",
    "Wide column databases can be thought of as tables where the data in each column can vary from row to row.\n",
    "\n",
    "- Cassandra\n",
    "- Initial release: 2008\n",
    "\n",
    "Cassandra was initially developed internally at Facebook and was later released as an open source software, eventually being picked up and maintained by the Apache Foundation. It was developed for handling large amounts of data to be distrubted across multiple servers. It is notable for being particualrly reliable and not having a single failure point.\n",
    "\n",
    "#### Graph Databases\n",
    "Graph databases expand upon the idea of document databases, adding in the concept of relations between documents. This makes certain operations and mappings such as connectivity of the graph of data very easy. However, individual data nodes may not be indexed which can mean that they are not directly accessible on their own but must be accessed via their relationship to more central objects.\n",
    "\n",
    "- Neo4j\n",
    "- Initial release: 2007\n",
    "\n",
    "Neo4j is probably the most popular graph database. It stores all its data as nodes, edges or attributes.\n",
    "\n",
    "- GraphQL\n",
    "- Initial release: 2015\n",
    "\n",
    "GraphQL was developed internally at Facebook and allows users to define specific data structures when requesting data from servers.\n",
    "\n",
    "#### Choosing an Appropriate Database\n",
    "There are many consideration when choosing a database including the size of the project, anticipated use cases, and development costs. One obvious and straightforward consideration is training and familiarity. This contributes to the popularity of SQL. Size and use cases are also incredibly imporatant considerations. For personal projects or small businesses, you may not even need a database and can perhaps simply use a csv or json file. As data grows, a database management system is often needed. Until scale continues to grow, any of these choices could meet needs. One of the biggest drawbacks of relational databases such as sql is that they don't scale well horizontally (such as adding columns). In such scenarios, some of the alternative models provide more computationally effective solutions at scale.\n",
    "\n",
    "#### Additional Resources\n",
    "Check out https://db-engines.com/en/ranking for a ranking of various databases as well as much more information about them!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
