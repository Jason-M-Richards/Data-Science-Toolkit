{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Cheat Sheet\n",
    "http://www.sqltutorial.org/wp-content/uploads/2016/04/SQL-cheat-sheet.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLite3\n",
    "\n",
    "#### Working with SQLite3 DBs in Jupyter Notebook\n",
    "\n",
    "    #First we import the sqlite3 module\n",
    "    ```python\n",
    "    #import sqlite3\n",
    "    ```\n",
    "\n",
    "    #Next we create our connection to the sqlite database file `pet_database.db` by using the method `.connect()` and the file name we would like for our database.\n",
    "    ```python\n",
    "    connection = sqlite3.connect('pet_database.db')\n",
    "    ```\n",
    "\n",
    "    #Then we create the *cursor* which we will use to execute SQL statements\n",
    "    ```python\n",
    "    cursor = connection.cursor()\n",
    "    ```\n",
    "\n",
    "    #Finally, when we want to execute our SQL statements we reference our SQL cursor object and call the method `.execute()` with our SQL statement as the argument\n",
    "    ```python\n",
    "    sql_return = cursor.execute('''SQL statement GOES here;''')\n",
    "    ```\n",
    "    To see a list of the information we retrieved from our SQL statement, we can take our `sql_return` variable and call the method `.fetchall()`, which will return a list of records (if we are executing a `SELECT` statement.\n",
    "    \n",
    "    #creating a table CATS with ID column as primary key using integers, a NAME column using text and an AGE column using integers\n",
    "    cursor.execute('''\n",
    "                CREATE TABLE cats (\n",
    "                id INTEGER PRIMARY KEY,\n",
    "                name TEXT, \n",
    "                age INTEGER\n",
    "                );'''\n",
    "               ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types\n",
    "TEXT, INTEGER, REAL(FLOAT), BLOB(BINARY DATA)\n",
    "\n",
    "### Primary and Foreign Keys\n",
    "Primary Key\t\n",
    "- Primary key uniquely identify a record in the table.\t\n",
    "- Primary Key can't accept null values.\t\n",
    "- By default, Primary key is clustered index and data in the database table is physically organized in the sequence of clustered index.\t\n",
    "- We can have only one Primary key in a table.\t\n",
    "    \n",
    "Foreign Key\n",
    "- Foreign key is a field in the table that is primary key in another table.\n",
    "- Foreign key can accept multiple null value.\n",
    "- Foreign key do not automatically create an index, clustered or non-clustered. You can manually create an index on foreign key.\n",
    "- We can have more than one foreign key in a table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SQL syntax with `pandasql`\n",
    "\n",
    "Since SQL is such a powerful, comfortable tool for Data Scientists, some people had the bright idea of creating a library that lets users query DataFrames using SQL-style syntax.  This library is called [pandasql]( https://pypi.org/project/pandasql/ ).\n",
    "\n",
    "We can install `pandasql` using the bash comman `pip install pandasql`.\n",
    "\n",
    "#### Importing pandasql\n",
    "\n",
    "In order to use `pandasql`, we need to start by importing a `sqldf` object from `pandasql`\n",
    "\n",
    "    ```python\n",
    "    from pandasql import sqldf\n",
    "    ```\n",
    "\n",
    "Next, we'll write a lambda function that will make it quicker and easier to write queries.  Normally, we would have to pass in the global variables every time we use an object.  In order to avoid doing this every time, we'll write a lambda that does this for us. \n",
    "\n",
    "    ```python\n",
    "    pysqldf = lambda q: sqldf(q, globals())\n",
    "    ```\n",
    "\n",
    "Now, when we pass a query into `pysqldf`, the lambda will also pass along the globals for us, saving us that repetitive task. \n",
    "\n",
    "#### Writing Queries\n",
    "\n",
    "To write a query, we just format it as a multi-line string!\n",
    "\n",
    "    ```python\n",
    "    q = \"\"\"SELECT\n",
    "            m.date, m.beef, b.births\n",
    "         FROM\n",
    "            meats m\n",
    "         INNER JOIN\n",
    "            births b\n",
    "               ON m.date = b.date;\"\"\"\n",
    "    ```\n",
    "\n",
    "In order to query DataFrames, we can just pass in the query string we've created to our `sqldf` object that we stored in `pysqldf`.  This will return a DataFrame.  \n",
    "\n",
    "    ```python\n",
    "    results = pysqldf(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization in Databases\n",
    "\n",
    "#### What is Database Normalization?\n",
    "Database normalization refers to the practice of storing data across one or more tables based on the information that data contains.\n",
    "\n",
    "#### Benefits of Database Normalization\n",
    "- 1. Minimize Duplicate Data\n",
    "- 2. Minimize Data Modification Issues\n",
    "- 3. Simplifying Queries\n",
    "\n",
    "#### Types of Normal Forms\n",
    "1st Normal Form: All rows have the same number of columns. No column names are repeated.\n",
    "\n",
    "2nd Normal Form: Meets the specifications of 1st normal form, plus all column data depends on the entire primary key, and not just part (remember, primary keys can be a composite of 2 or more columns in a table!)\n",
    "\n",
    "3rd Normal Form: Meets the specifications of 2nd normal form, plus no column depends on other columns. Each column in the table depends on the primary key, the whole primary key, and nothing but the primary key.\n",
    "\n",
    "#### Table Relationships\n",
    "\n",
    "##### One-to-One Relationships\n",
    "In one-to-one relationships, an entity in a table is connected to exactly one entity in a corresponding table through a foreign key.\n",
    "\n",
    "##### One-to-Many Relationships\n",
    "In one-to-many relationships, an entity in a table can be connected to one or more entities in a corresponding table through a foreign key.\n",
    "\n",
    "##### Many-to-Many Relationships\n",
    "In many-to-many relationships, an multiple entities in a table can be connected to one or more of the same entities in a corresponding table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entity Relationship Diagram\n",
    "\n",
    "https://yintingchou.com/posts/2017-09-01-learning-microsoft-sql-server/ERD.png\n",
    "\n",
    "#### ERD relationship notation\n",
    "\n",
    "https://d2slcw3kip6qmk.cloudfront.net/marketing/pages/chart/ER-diagram-symbols-and-meaning/ERD_notation-416x315.PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQLalchemy and Object Relation Mappers (ORM)\n",
    "\n",
    "#### Defining Our Mappings\n",
    "We'll begin by importing everything we need to create our database and structure our mappings so that they look like the tables in the ERD.\n",
    "\n",
    "    #import packages and decalre a base\n",
    "    from sqlalchemy import *\n",
    "    from sqlalchemy.orm import relationship #to create relationships\n",
    "    from sqlalchemy.ext.declarative import declarative_base #to declare a base\n",
    "    Base = declarative_base()\n",
    "\n",
    "#### Creating Class Mappings\n",
    "\n",
    "https://www.sqlalchemy.org/\n",
    "\n",
    "In order to set up our classes, define:\n",
    "\n",
    "- The __tablename__ for each class\n",
    "- The attributes of each class, which will be Column objects\n",
    "- The relationship that each class has to other classes\n",
    "\n",
    "\n",
    "        #Complete the Customer, ShoppingCart, and Item classes.\n",
    "    \n",
    "        class Customer(Base):\n",
    "            __tablename__ = 'customer'\n",
    "\n",
    "            id = Column(Integer, primary_key=True)\n",
    "            name = Column(String)\n",
    "            cart_id = Column(Integer, ForeignKey('shoppingCart.id'))\n",
    "\n",
    "            # Create 1-to-1 relationship with ShoppingCart, as shown in the SQLAlchemy documentation\n",
    "            shoppingCart = relationship('ShoppingCart', uselist=False, back_populates='customer')\n",
    "        class ShoppingCart(Base):\n",
    "            __tablename__ = \"shoppingCart\"\n",
    "\n",
    "            id = Column(Integer, primary_key=True)\n",
    "            item_id = Column(Integer, ForeignKey('item.id'))\n",
    "            # Create 1-to-1 relationship with Customer\n",
    "            customer = relationship('Customer', uselist=False, back_populates='shoppingCart')\n",
    "            # Create 1-to-many relationship with Item\n",
    "            items = relationship('Item')\n",
    "        class Item(Base):\n",
    "            __tablename__ = 'item'\n",
    "\n",
    "            id = Column(Integer, primary_key=True)\n",
    "            description = Column(String)\n",
    "            price = Column(Float)\n",
    "\n",
    "        #Creating Our Database\n",
    "        engine = create_engine('sqlite:///shopping_cart.db', echo=True)\n",
    "        Base.metadata.create_all(engine)\n",
    "\n",
    "        #create some objects, and then populate the database with them.\n",
    "\n",
    "        customer1 = Customer(name=\"Jane\")\n",
    "        item1 = Item(description=\"widget\", price=9.99)\n",
    "        cart1 = ShoppingCart(customer=customer1, items = item1)\n",
    "        customer1.shoppingCart = cart1\n",
    "        \n",
    "        #add our new data to our database tables by creating a session object.\n",
    "        from sqlalchemy.orm import sessionmaker, Session\n",
    "        Session = sessionmaker(bind=engine)\n",
    "        session = Session()\n",
    "\n",
    "        #add items to our database one at a time by passing them in as a parameter to session.add(). \n",
    "        #add multiple items by passing them as a list into the add_all() method.\n",
    "        session.add_all([customer1, cart1, item1])\n",
    "\n",
    "        #see all the items that have been added by checking the session objectthe cell below.\n",
    "        #session.new\n",
    "\n",
    "\n",
    "        #commit our objects to push them to the database.\n",
    "        session.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying with SQLalchemy\n",
    "\n",
    "    #Connecting to the Database\n",
    "    import sqlalchemy\n",
    "    from sqlalchemy import create_engine\n",
    "    from sqlalchemy.orm import Session, sessionmaker\n",
    "    engine = create_engine(\"sqlite:///Northwind_small.sqlite\", echo=True)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    #Get Table Names and Table Information\n",
    "    from sqlalchemy import inspect\n",
    "    inspector = inspect(engine)\n",
    "    print(inspector.get_table_names())\n",
    "\n",
    "    #function to print out the name and type of each column in a well-formatted way.\n",
    "    def get_columns_info(col_name):\n",
    "        cols_list = inspector.get_columns(col_name)\n",
    "\n",
    "        print(\"Table Name: {}\".format(col_name))\n",
    "        print(\"\")\n",
    "\n",
    "        for column in cols_list:\n",
    "            print(\"Name: {} \\t Type: {}\".format(column['name'], column['type']))\n",
    "    get_columns_info('Employee')\n",
    "\n",
    "    #Connecting and Executing Raw SQL Statements\n",
    "    con = engine.connect()\n",
    "    rs = con.execute(\"SELECT * FROM Customer LIMIT 5\")\n",
    "    print(rs.fetchall())\n",
    "\n",
    "    #Storing data in Pandas DataFrame\n",
    "    import pandas as pd\n",
    "    rs = con.execute(\"SELECT firstname, lastname, title from Employee\")\n",
    "    df = pd.DataFrame(rs.fetchall())\n",
    "    df.head()\n",
    "\n",
    "\n",
    "    Nice! We can now read our results. However, the columns of our DataFrame aren't labeled. Luckily, pandas plays nicely with the sqlalchemy library, and can actually execute sql queries!\n",
    "\n",
    "    #query to select all orders from customer VINET\n",
    "    df = pd.read_sql_query(\"SELECT * FROM [Order] WHERE CUSTOMERId = 'VINET'\", engine)\n",
    "    df.head()\n",
    "\n",
    "\n",
    "    #Executing JOIN Statements\n",
    "    df = pd.read_sql_query(\"\"\"SELECT o.ID, c.CompanyName, Count(*) num_orders FROM [Order] \\\n",
    "    o INNER JOIN Customer c on o.CustomerID = c.ID GROUP BY c.CompanyName ORDER BY num_orders DESC\"\"\", engine)\n",
    "    df.head()\n",
    "\n",
    "    #JOINs with Many-To-Many Relationships\n",
    "    q = \"\"\"SELECT LastName, FirstName, COUNT(*) as TerritoriesAssigned from \\\n",
    "    Employee \\\n",
    "    JOIN EmployeeTerritory et on Employee.Id = et.employeeId \\\n",
    "    GROUP BY Employee.lastname \\\n",
    "    ORDER BY TerritoriesAssigned DESC\"\"\"\n",
    "    df2 = pd.read_sql_query(q, engine)\n",
    "    df2.head()\n",
    "\n",
    "    #create mappings of tables to objects in python to use ORM\n",
    "    from sqlalchemy import MetaData\n",
    "    from sqlalchemy.ext.automap import automap_base\n",
    "    metadata = MetaData()\n",
    "    metadata.reflect(engine)\n",
    "    Base = automap_base(metadata=metadata)\n",
    "    Base.prepare()\n",
    "    Employee, Customer = Base.classes.Employee, Base.classes.Customer\n",
    "\n",
    "#### Writing Basic Queries\n",
    "\n",
    "    #for loop that iterates through the results returned by a session.query() of the Employee table and orders the results by the Employee's .HireDate attribute.\n",
    "    for instance in session.query(Employee).order_by(Employee.HireDate):\n",
    "        print(\"Name: {}, {}  Hired: {}\".format(instance.LastName, instance.FirstName, instance.HireDate))\n",
    "\n",
    "    Implicit JOINs using .filter()\n",
    "    One great benefit of using session.query() to query our data is that we can easily execute implicit joins by making use of the .filter() method.\n",
    "\n",
    "    So far we've only explicitly specified mappings for the Employee and Customer classes. We'll need to do this now for the Product and Category classes before we can use them with session.query().\n",
    "\n",
    "    #set the mappings for Product and Category.\n",
    "    Product, Category = Base.classes.Product, Base.classes.Category\n",
    "\n",
    "    #for loop that iterates through all results returned from a query of Products and Categories and use the .filter() method to only include cases where the Product's .CategoryID matches the Category's .Id attribute.\n",
    "    for p, c in session.query(Product, Category).filter(Product.CategoryId==Category.Id).all():\n",
    "        print(\"Product Name: {}  Category Name: {}\".format(p.ProductName, c.CategoryName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Server Error Handling\n",
    "\n",
    "#### Error Anatomy\n",
    "- Message # - can be 1-499999\n",
    "    - can create errors starting with 50001\n",
    "- Level\n",
    "    - 0-10 (informational)\n",
    "    - 11-16 (errors that can be corrected\n",
    "    - 17-24 (fatal errors, software problems)\n",
    "        - error levels <11 and > 20 are uncatchable by a TRY-CATCH block\n",
    "- State\n",
    "    - 1 - SQL Server displays error\n",
    "    - can assign values 0-255\n",
    "- Line\n",
    "    - which line the error occured\n",
    "- Procedure \n",
    "    - procedure that caused the error\n",
    "    \n",
    "#### TRY...CATCH syntax\n",
    "- can be nested\n",
    "   \n",
    "    BEGIN TRY\n",
    "        #enclose statements within the try block\n",
    "        INSERT INTO products (product_name, stock, price)\n",
    "        VALUES ('product_name', 10, 3499)\n",
    "        SELECT 'Product inserted correctly!' AS message;\n",
    "    END TRY\n",
    "    BEGIN CATCH\n",
    "        #place error handling code in CATCH block\n",
    "        SELECT 'An error occured! You are in the CATCH block!' AS message;\n",
    "    END CATCH;\n",
    "    #Error in TRY block -> CATCH block takes control, if no error, CATCH is skipped\n",
    "    \n",
    "#### Functions That Provide Error Info.\n",
    "- functions that can be ran when in the CATCH block\n",
    "- ERROR_NUMBER() - returns the number of an error\n",
    "- ERROR_SEVERITY() - returns severity (11-19)\n",
    "- ERROR_STATE() - returns state of the error\n",
    "- ERROR_LINE() - returns the line where error occured\n",
    "- ERROR_PROCEDURE() - returns the name of the stored procedure/trigger. NULL if no value\n",
    "- ERROR_MESSAGE() - returns the text of the error message\n",
    "- EXAMPLE\n",
    "\n",
    "            -- Set up the TRY block\n",
    "        BEGIN TRY  \t\n",
    "            SELECT 'Total: ' + SUM(price * quantity) AS total\n",
    "            FROM orders  \n",
    "        END TRY\n",
    "        -- Set up the CATCH block\n",
    "        BEGIN CATCH  \n",
    "            -- Show error information.\n",
    "            SELECT  ERROR_NUMBER() AS number,  \n",
    "                    ERROR_SEVERITY() AS severity_level,  \n",
    "                    ERROR_STATE() AS state,\n",
    "                    ERROR_LINE() AS line,  \n",
    "                    ERROR_MESSAGE() AS message; \t\n",
    "        END CATCH \n",
    "        \n",
    "#### RAISERROR\n",
    "- create an error statement\n",
    "- used in the TRY block\n",
    "\n",
    "        RAISERROR('error_message', severity, state)\n",
    "        # can use formatting\n",
    "        RAISERROR('error %s message %d, severity, state, '%s_string', %d number)\n",
    "        # can use message number instead of message string\n",
    "        RAISERROR(message_number, severity, state) #error numbers and associated messages are stored in sys.messages\n",
    "    \n",
    "#### THROW\n",
    "\n",
    "- Microsoft suggests using throw for newer programs\n",
    "- works within or without the CATCH block\n",
    "- must be used in CATCH block if using only THROW; # no arguments\n",
    "- defaults severity to 16\n",
    "\n",
    "        THROW error_number, message, state;\n",
    "\n",
    "##### customizing THROW statements\n",
    "- using a variable and the CONCAT function\n",
    "\n",
    "        -- Set @first_name to 'Pedro'\n",
    "        DECLARE @first_name NVARCHAR(20) = 'Pedro';\n",
    "        -- Concat the message\n",
    "        DECLARE @my_message NVARCHAR(500) =\n",
    "            CONCAT('There is no staff member with ', @first_name, ' as the first name.');\n",
    "\n",
    "        IF NOT EXISTS (SELECT * FROM staff WHERE first_name = @first_name)\n",
    "            -- Throw the error\n",
    "            THROW 50000, @my_message, 1;\n",
    "            \n",
    "- using FORMATMESSAGE\n",
    "\n",
    "        #with message string\n",
    "        DECLARE @product_name AS NVARCHAR(50) = 'Trek CrossRip+ - 2018';\n",
    "        DECLARE @number_of_sold_bikes AS INT = 10;\n",
    "        DECLARE @current_stock INT;\n",
    "        -- Select the current stock\n",
    "        SELECT @current_stock = stock FROM products WHERE product_name = @product_name;\n",
    "        DECLARE @my_message NVARCHAR(500) =\n",
    "            -- Customize the message\n",
    "            FORMATMESSAGE('There are not enough %s bikes. You only have %d in stock.', @current_stock, @product_name);\n",
    "\n",
    "        IF (@current_stock - @number_of_sold_bikes < 0)\n",
    "            -- Throw the error\n",
    "            THROW 50000, @my_message, 1;\n",
    "            \n",
    "            #example with message number\n",
    "            #first, message needs to be set in system\n",
    "            EXEC sp_addmessage @msgnum = 50002, @severity = 16, @msgtext = 'There are not enough %s bikes. You only have %d in stock.', @lang = N'us_english';\n",
    "\n",
    "        DECLARE @product_name AS NVARCHAR(50) = 'Trek CrossRip+ - 2018';\n",
    "        DECLARE @number_of_sold_bikes AS INT = 10;\n",
    "        DECLARE @current_stock INT;\n",
    "        SELECT @current_stock = stock FROM products WHERE product_name = @product_name;\n",
    "        DECLARE @my_message NVARCHAR(500) =\n",
    "            -- Prepare the error message\n",
    "            FORMATMESSAGE(50002, @product_name, @current_stock );\n",
    "\n",
    "        IF (@current_stock - @number_of_sold_bikes < 0)\n",
    "            -- Throw the error\n",
    "            THROW 50000, @my_message, 1;\n",
    "            \n",
    "### Transactions\n",
    "- execution of one or more statements where all or none of the statements are executed\n",
    "- transactions are saved in a separate table\n",
    "\n",
    "        #start a transaction\n",
    "        BEGIN TRAN/TRANSACTION trans_name or trans_var;\n",
    "        #end a successful transaction\n",
    "        COMMIT TRAN/TRANSACTION trans_name or trans_var\n",
    "        WITH(DELAYED_DURABILITY = OFF/ON;\n",
    "        #revert or fix a transaction\n",
    "        ROLLBACK TRAN/TRANSACTION trans_name or trans_var;\n",
    "        \n",
    "- example where a transaction is performed and if errors are present, it will rollback the transaction\n",
    "\n",
    "        BEGIN TRY  \n",
    "            BEGIN TRAN;\n",
    "                UPDATE accounts SET current_balance = current_balance - 100 WHERE account_id = 1;\n",
    "                INSERT INTO transactions VALUES (1, -100, GETDATE());\n",
    "        \n",
    "                UPDATE accounts SET current_balance = current_balance + 100 WHERE account_id = 5;\n",
    "                INSERT INTO transactions VALUES (5, 100, GETDATE());\n",
    "            COMMIT;\n",
    "        END TRY\n",
    "        BEGIN CATCH  \n",
    "            ROLLBACK;\n",
    "        END CATCH\n",
    "        \n",
    "##### @@TRANCOUNT \n",
    "- number of BEGIN TRAN statements that are active in your current connection\n",
    "    - BEGIN TRAN statements increase count +1\n",
    "    - COMMIT TRAN statements decrease count -1\n",
    "    - ROLLBACK TRAN statements decrease count to 0 except if there is a savepoint\n",
    "\n",
    "##### savepoints \n",
    "- allow to rollback to a savepoint\n",
    "\n",
    "        SAVE TRAN savepoint_name\n",
    "        \n",
    "##### XACT_ABORT\n",
    "- specifies whether current transaction will be auto rolled back when an error occurs\n",
    "\n",
    "       #OFF is default setting\n",
    "       SET XACT_ABORT ON/OFF\n",
    "\n",
    "##### XACT_STATE\n",
    "- returns 0 when no transactions\n",
    "- returns 1 when open and commitable trans.\n",
    "- -1 when open and uncommitable trans.\n",
    "\n",
    "#### Concurrency\n",
    "- two or more transactions that read/change shared data at the same time\n",
    "- may want to isolate transactions\n",
    "\n",
    "#### Transaction Isolation\n",
    "\n",
    "        SET TRANSACTION ISOLATION LEVEL selected_level\n",
    "\n",
    "##### READ COMMITTED\n",
    "- default isolation level\n",
    "- cant read data modified by other transaction that hasnt been committed or rolled back\n",
    "\n",
    "##### READ UNCOMMITTED\n",
    "- least restrictive\n",
    "- read rows modified without being committed\n",
    "\n",
    "##### REPEATABLE READ\n",
    "- same restriction as READ COMMITTED +\n",
    "- if some data is read, other trans. cannot modify that data until REPEATABLE READ transaction finishes\n",
    "\n",
    "##### SERIALIZABLE\n",
    "- most restrictive\n",
    "- querying with a WHERE clause based on index range will lock only those records\n",
    "- if no query, locks entire table\n",
    "\n",
    "##### SNAPSHOT\n",
    "- every modification is stored in tempDB table\n",
    "- only see committed changes that occured before the start of SNAPSHOT transaction and own changes\n",
    "- similar restriction level as SERIALIZABLE\n",
    "- using the ALTER DATABASE command, can allow SNAPSHOT for READ_COMMITTED \n",
    "- WITH (NOLOCK)\n",
    "    - used to read uncommited data\n",
    "    - applies to a specific table\n",
    "       \n",
    "       \n",
    "           #update a database\n",
    "            ALTER DATABASE myDatabaseName SET ALLOW_SNAPSHOT_ISOLATION ON;\n",
    "\n",
    "            SET TRANSACTION ISOLATION LEVEL SNAPSHOT\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Query Best Practices\n",
    "\n",
    "#### General Guidelines\n",
    "- SQL input is case insensitive\n",
    "- consistency is important\n",
    "- use UPPER CASE for all SQL syntax\n",
    "- create new lines for each processing syntax (SELECT, FROM, WHERE, etc)\n",
    "- indent code:\n",
    "    - ON statements\n",
    "    - AND/OR conditions\n",
    "    - subqueries\n",
    "    - to avoid long lines of single code\n",
    "- complete query using ;\n",
    "- alias where required using AS\n",
    "- add block comments (/* text */)\n",
    "- add single line comments (--)\n",
    "\n",
    "#### Aliasing (AS)\n",
    "- used in queries to identify:\n",
    "    - tables\n",
    "    - columns\n",
    "    - sub-queries\n",
    "- temporary, only applied when query is run\n",
    "\n",
    "        SELECT Team, \n",
    "        ROUND(AVG(BMI),2) AS AvgTeamBMI -- Alias the new column\n",
    "        FROM PlayerStats AS ps -- Alias PlayerStats table\n",
    "        \n",
    "#### Syntax Order\n",
    "\n",
    "##### processing order\n",
    "- 1 FROM\n",
    "- 2 ON\n",
    "- 3 JOIN\n",
    "- 4 WHERE\n",
    "- 5 GROUP BY\n",
    "- 6 HAVING\n",
    "- 7 SELECT\n",
    "- 8 DISTINCT\n",
    "- 9 ORDER BY\n",
    "- 10 TOP\n",
    "\n",
    "#### WHERE\n",
    "- filters out individual rows with a condition (increases processing time)\n",
    "- avoid using calculations or functions\n",
    "- use wild card strings 'WildCard%'\n",
    "\n",
    "#### HAVING\n",
    "- also used to filter query\n",
    "- filters groups or multiple rows\n",
    "- can only be applied to a numeric column in an aggregate function filter\n",
    "\n",
    "#### SELECT\n",
    "- SELECT * can be computationally expensive for large tables and in joins returns duplicates of joining columns\n",
    "\n",
    "#### TOP (MSSQL) ROWNUM(Oracle) LIMIT(PostgreSQL)\n",
    "- used after SELECT to limit rows returned\n",
    "- can also be used in conjunction with PERCENT (proportion of rows)\n",
    "- combine with ORDER BY DESC to get bottom rows\n",
    "\n",
    "#### Managing Duplicates\n",
    "- most common occurence is when joining tables\n",
    "- may be alternate to using DISTINCT, UNION\n",
    "\n",
    "##### DISTINCT\n",
    "- helps remove duplicates\n",
    "- does not work with aggregate functions (use GROUP BY)\n",
    "\n",
    "##### UNION\n",
    "- removes duplicates when appending tables\n",
    "- UNION ALL does not remove duplicates\n",
    "\n",
    "#### Sub-queries\n",
    "- uses its own SELECT statement\n",
    "- returns to the outer query (sub-query runs first)\n",
    "- can start with FROM, WHERE, SELECT\n",
    "##### uncorrelated (WHERE, FROM)\n",
    "- does not contain a reference to the outer query\n",
    "- can run idependently\n",
    "##### correlated (WHERE, SELECT)\n",
    "- include reference to outer query \n",
    "- cannot run without outer query\n",
    "- INNER JOIN can in many cases replace a correlated sub-query\n",
    "\n",
    "#### INTERSECT\n",
    "- finds common information between tables\n",
    "- numbers and orders of columns must be the same\n",
    "\n",
    "        SELECT Capital\n",
    "        FROM Nations -- Table with capital cities\n",
    "\n",
    "        INTERSECT -- Add the operator to compare the two queries\n",
    "\n",
    "        SELECT NearestPop -- Add the city name column\n",
    "        FROM Earthquakes;\n",
    "\n",
    "#### EXCEPT\n",
    "- finds uncommon information between tables\n",
    "- numbers and orders of columns must be the same\n",
    "\n",
    "        SELECT Code2 -- Add the country code column\n",
    "        FROM Nations\n",
    "\n",
    "        EXCEPT -- Add the operator to compare the two queries\n",
    "\n",
    "        SELECT Country \n",
    "        FROM Earthquakes; -- Table with country codes\n",
    "        \n",
    "#### EXISTS, NOT EXISTS\n",
    "- similar to INTERSECT, EXCEPT for finding common data in a sub-query\n",
    "- preferred method over IN \n",
    "\n",
    "        -- Second attempt\n",
    "        SELECT CountryName,   \n",
    "               Capital,\n",
    "               Pop2016, -- 2016 country population\n",
    "               WorldBankRegion\n",
    "        FROM Nations AS n\n",
    "        WHERE EXISTS -- Add the operator to compare queries\n",
    "              (SELECT 1\n",
    "               FROM Earthquakes AS e\n",
    "               WHERE n.Capital = e.NearestPop); -- Columns being compared\n",
    "\n",
    "#### IN, NOT IN\n",
    "- similar to EXISTS, but need to specify the column to match on\n",
    "\n",
    "        SELECT WorldBankRegion,\n",
    "       CountryName\n",
    "        FROM Nations\n",
    "        WHERE Code2 NOT IN -- Add the operator to compare queries\n",
    "            (SELECT CountryCode -- Country code column\n",
    "             FROM Cities);\n",
    "             \n",
    " #### INNER JOIN\n",
    " - joins matching data in related tables\n",
    " \n",
    "         -- Second query\n",
    "        SELECT t.TeamName,\n",
    "               t.TeamCode,\n",
    "               t.City,\n",
    "               e.Date,\n",
    "               e.place, -- Place description\n",
    "               e.CountryCode -- Country code\n",
    "        FROM Teams AS t\n",
    "        INNER JOIN Earthquakes AS e -- Operator to compare tables\n",
    "              ON t.City = e.NearestPop\n",
    "              \n",
    " #### LEFT OUTER JOIN\n",
    " - exclusive - checks for data left query not in right query - need to add IS NULL\n",
    " - inclusive - returns all rows in left query\n",
    " \n",
    "         -- Second attempt\n",
    "        SELECT c.CustomerID,\n",
    "               c.CompanyName,\n",
    "               c.ContactName,\n",
    "               c.ContactTitle,\n",
    "               c.Phone \n",
    "        FROM Customers c\n",
    "        LEFT OUTER JOIN Orders o\n",
    "            ON c.CustomerID = o.CustomerID\n",
    "        WHERE c.Country = 'France'\n",
    "            AND o.CustomerID IS NULL; -- Filter condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "- measuring performance\n",
    "\n",
    "#### STATISTICS TIME\n",
    "- time in ms\n",
    "- CPU time - time taken by server processors to process the query\n",
    "- elapsed time - total duration of the query (best measure to rely on)\n",
    "- need to turn on before query\n",
    "- does not need to be rerun when ON\n",
    "        \n",
    "        SET STATISTICS TIME ON #turn on\n",
    "        SET STATISTICS TIME OFF #turn off\n",
    "\n",
    "#### STATISTICS IO\n",
    "- data stored stored in 8kB size 'pages'\n",
    "- 'page' can only belong to one table\n",
    "- need to turn on before query\n",
    "- logical reads - # of pages for that table\n",
    "\n",
    "        SET STATISTICS IO ON #turn on\n",
    "        SET STATISTICS IO OFF #turn off\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexes\n",
    "- structure to improve speed of accessing data from a table\n",
    "- can locate data quickly w/o having to scan the entire table\n",
    "- applied to table columns\n",
    "\n",
    "#### Clustered\n",
    "- similar to a dictionary setup\n",
    "- queries are run faster\n",
    "\n",
    "#### Nonclustered\n",
    "- similar to the index at the back of a book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Plans\n",
    "- shows if indexes were used\n",
    "- the types of joins used\n",
    "- the location and relative costs of filters, sorting, aggregations\n",
    "- can access via SSMS toolbar menu\n",
    "- read from right->left\n",
    "- width of arrow represents data amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Triggers\n",
    "- special type of stored procedure\n",
    "- executed when an event occurs in the server\n",
    "- used to prevent or add executions to statements when changes occur to DB\n",
    "- cannot call other triggers\n",
    "- dont allow parameters or transactions\n",
    "- cannot return values\n",
    "- can calculate column values\n",
    "- can use columns from other tables for calculations\n",
    "- used for auditing and integrity enforcement\n",
    "- types of triggers\n",
    "    - DML - data manipulation language\n",
    "        - INSERT, UPDATE, DELETE\n",
    "    - DDL - data definition language\n",
    "        - CREATE, ALTER, DROP\n",
    "    - Logon \n",
    "        - LOGON events\n",
    "    - AFTER trigger\n",
    "        - additional statement triggered after initial statement executes\n",
    "    - INSTEAD OF\n",
    "        - prevents original execution with a replacement\n",
    "        \n",
    "#### CREATE TRIGGER\n",
    "- creates a trigger\n",
    "- needs to be attached to a table\n",
    "\n",
    "        -- Create a new trigger that fires when deleting data\n",
    "        CREATE TRIGGER PreventDiscountsDelete\n",
    "        ON Discounts\n",
    "        -- The trigger should fire instead of DELETE\n",
    "        INSTEAD OF DELETE\n",
    "        AS\n",
    "            PRINT 'You are not allowed to delete data from the Discounts table.';\n",
    "            \n",
    "#### Trigger Alternatives\n",
    "- Stored Procedues\n",
    "    - run when called explicitly\n",
    "    - can call other stored procedures\n",
    "    - accept parameters and transactions\n",
    "    - can return values as outputs\n",
    "    - used for general tasks\n",
    "- Computed Columns\n",
    "    - calculate column values\n",
    "    - use columns only from the same table\n",
    "    - defined when creating table\n",
    "    \n",
    "#### AFTER TRIGGER\n",
    "- used with INSERT, UPDATE, DELETE statements\n",
    "- use cases\n",
    "    - history of row changes\n",
    "    - audit changes\n",
    "    - send notifications\n",
    "- can be used with DML and DDL\n",
    "- need a target table\n",
    "- need a description of the trigger\n",
    "- need to define which statement fires the trigger (INSERT, DELETE, UPDATE)\n",
    "- needs to have a name\n",
    "\n",
    "        -- Create the trigger and trigger name\n",
    "        CREATE TRIGGER TrackRetiredProducts\n",
    "        -- Specify table\n",
    "        ON Products\n",
    "        -- specify trigger firing statement\n",
    "        AFTER DELETE\n",
    "        -- statement to be perfromed\n",
    "        AS\n",
    "            INSERT INTO RetiredProducts (Product, Measure)\n",
    "            SELECT Product, Measure\n",
    "            FROM deleted;\n",
    "            \n",
    "#### INSTEAD OF\n",
    "- can only be used on DML statements\n",
    "- use cases\n",
    "    - prevent certain operations and notify admin\n",
    "- need a target table\n",
    "- need a description of the trigger\n",
    "- need to define which statement fires the trigger (INSERT, DELETE, UPDATE)\n",
    "- needs to have a name\n",
    "\n",
    "            -- Create the trigger and trigger name\n",
    "        CREATE TRIGGER PreventOrdersUpdate\n",
    "        -- specify table\n",
    "        ON Orders\n",
    "        -- specify trigger firing statement\n",
    "        INSTEAD OF UPDATE\n",
    "        -- statement to be perfromed\n",
    "        AS\n",
    "            RAISERROR ('Updates on \"Orders\" table are not permitted.\n",
    "                        Place a new order to add new products.', 16, 1);\n",
    "                        \n",
    "#### DDL triggers\n",
    "- works with CREATE, ALTER, DROP statements\n",
    "- can only be used with AFTER trigger, not INSTEAD OF\n",
    "- use cases\n",
    "    - database level\n",
    "        - _TABLE, _VIEW, _INDEX, _STATISTICS, _ROLE_MEMBER\n",
    "        - auditing\n",
    "    - server level\n",
    "        - _DATABASE, _SERVER, _CREDENTIAL\n",
    "        - prevention\n",
    "- use FOR instead of AFTER for DDL specific trigger\n",
    "- since INSTEAD OF cannot be used, should use ROLLBACK at the end of the trigger to undo the previous statement\n",
    "\n",
    "        -- FOR example at DATABASE level\n",
    "        CREATE TRIGGER TrackTableChanges\n",
    "        ON DATABASE\n",
    "        FOR CREATE_TABLE,\n",
    "        ALTER_TABLE,\n",
    "        DROP_TABLE\n",
    "        AS\n",
    "        INSERT INTO TablesChangeLog (EventData, ChangedBy)\n",
    "        VALUES (EVENTDATA(), USER);\n",
    "        \n",
    "       -- Create a trigger to prevent database deletion\n",
    "        CREATE TRIGGER PreventDatabaseDelete\n",
    "        -- Attach the trigger at the server level\n",
    "        ON ALL SERVER\n",
    "        FOR DROP_DATABASE\n",
    "        AS\n",
    "           PRINT 'You are not allowed to remove existing databases.';\n",
    "           ROLLBACK;\n",
    "        \n",
    "#### Logon triggers\n",
    "- activated by lOGON event\n",
    "- after authentication - before connection\n",
    "\n",
    "        -- Create a trigger firing when users log on to the server\n",
    "        CREATE TRIGGER LogonAudit\n",
    "        -- Use ALL SERVER to create a server-level trigger\n",
    "        ON ALL SERVER WITH EXECUTE AS 'sa'\n",
    "        -- The trigger should fire after a logon\n",
    "        AFTER LOGON\n",
    "        AS\n",
    "            -- Save user details in the audit table\n",
    "            INSERT INTO ServerLogonLog (LoginName, LoginDate, SessionID, SourceIPAddress)\n",
    "            SELECT ORIGINAL_LOGIN(), GETDATE(), @@SPID, client_net_address\n",
    "            FROM SYS.DM_EXEC_CONNECTIONS WHERE session_id = @@SPID;\n",
    "            \n",
    "#### Trigger Limitations/Management\n",
    "- difficult to view and detect\n",
    "- invisible to client applications\n",
    "- hard to follow logic when troubleshooting\n",
    "- can make server run slower\n",
    "\n",
    "##### finding triggers\n",
    "\n",
    "    -- server level\n",
    "    SELECT * FROM sys.server_triggers\n",
    "    --database  or table level\n",
    "    SELECT * FROM sys.triggers\n",
    "    \n",
    "##### finding definitions\n",
    "\n",
    "    SELECT definition\n",
    "    FROM sys.sql_modules\n",
    "    WHERE object_id = OBJECT_ID('TriggerName')\n",
    "    \n",
    "##### sys.triggers and sys.server_triggers\n",
    "- object_id: unique identifier\n",
    "- parent_class: trigger type as integer (1- table; 0 - DB)\n",
    "- parent_class_desc: text description of trigger type\n",
    "- create_date - date created\n",
    "- modify_date - date of last modification\n",
    "- is_disabled: 1-yes, 0-no\n",
    "- is_instead_of_trigger: 1-INSTEAD OF, 0-AFTER\n",
    "\n",
    "##### sys.server_events and sys.server_trigger_events\n",
    "\n",
    "    SELECT * FROM sys.trigger_events;\n",
    "    \n",
    "- object_id: unique identifier  \n",
    "- type: event type as integer\n",
    "- type_desc: event type as description\n",
    "- event_group_type: event group type as integer\n",
    "- event_group_type_desc: event group type as description\n",
    "\n",
    "##### sys.trigger_event_types and sys.server_trigger_event_types\n",
    "- provides a list of all event types\n",
    "\n",
    "        SELECT * FROM sys.trigger_event_types\n",
    "        \n",
    "##### sys.dm_exec_trigger_stats\n",
    "- provides a table of trigger executions\n",
    "\n",
    "        SELECT * FROM sys.dm_exec_trigger_stats;\n",
    "\n",
    "#### Deleting Triggers\n",
    "\n",
    "    DROP TRIGGER TriggerName;\n",
    "    \n",
    "    -- delete DB trigger\n",
    "    DROP TRIGGER TriggerName\n",
    "    ON DATABASE;\n",
    "    \n",
    "    -- delete server trigger\n",
    "    DROP TRIGGER TriggerName\n",
    "    ON ALL SERVER;\n",
    "    \n",
    "#### Disable/Enable Trigger\n",
    "\n",
    "    DISABLE/ENABLE TRIGGER TriggerName\n",
    "    ON TableName;\n",
    "    \n",
    "- use ON DATABASE and ON ALL SERVER to disable at those levels (no need to specify table)\n",
    "    \n",
    "#### Altering Triggers\n",
    "\n",
    "    ALTER TRIGGER TriggerName\n",
    "    ON TableName\n",
    "    [trigger_statement]\n",
    "    \n",
    "#### Triggers Best Practices\n",
    "- well documented DB design\n",
    "- simple trigger designs\n",
    "- avoid trigger overuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NoSQL Database Types\n",
    "\n",
    "#### Key - Value DatabasesÂ¶\n",
    "Key value databases, are one of the most simplistic database systems, simply storing data as key-value pairs, just like python dictionaries. The most common implementation is Redis.\n",
    "\n",
    "- Redis\n",
    "- Initial release: 2009\n",
    "\n",
    "#### Document Model Databases\n",
    "Document model databases are a subclass of key-value databases. The initial concept is of documents such as json or xml. The database stores these documents using key-value pairs. However, unlike key-value databases, document model databases have the additional ability to access information within these documents directly.\n",
    "\n",
    "- MongoDB\n",
    "- Initial release: 2009\n",
    "\n",
    "MongoDB is one of the most popular sql alternatives. It represents data very similar to the JSON format we have been investigating today. It also supports a distributed model where data can be stored across multiple computers.\n",
    "\n",
    "#### Wide Column Databases\n",
    "Wide column databases can be thought of as tables where the data in each column can vary from row to row.\n",
    "\n",
    "- Cassandra\n",
    "- Initial release: 2008\n",
    "\n",
    "Cassandra was initially developed internally at Facebook and was later released as an open source software, eventually being picked up and maintained by the Apache Foundation. It was developed for handling large amounts of data to be distrubted across multiple servers. It is notable for being particualrly reliable and not having a single failure point.\n",
    "\n",
    "#### Graph Databases\n",
    "Graph databases expand upon the idea of document databases, adding in the concept of relations between documents. This makes certain operations and mappings such as connectivity of the graph of data very easy. However, individual data nodes may not be indexed which can mean that they are not directly accessible on their own but must be accessed via their relationship to more central objects.\n",
    "\n",
    "- Neo4j\n",
    "- Initial release: 2007\n",
    "\n",
    "Neo4j is probably the most popular graph database. It stores all its data as nodes, edges or attributes.\n",
    "\n",
    "- GraphQL\n",
    "- Initial release: 2015\n",
    "\n",
    "GraphQL was developed internally at Facebook and allows users to define specific data structures when requesting data from servers.\n",
    "\n",
    "#### Choosing an Appropriate Database\n",
    "There are many consideration when choosing a database including the size of the project, anticipated use cases, and development costs. One obvious and straightforward consideration is training and familiarity. This contributes to the popularity of SQL. Size and use cases are also incredibly imporatant considerations. For personal projects or small businesses, you may not even need a database and can perhaps simply use a csv or json file. As data grows, a database management system is often needed. Until scale continues to grow, any of these choices could meet needs. One of the biggest drawbacks of relational databases such as sql is that they don't scale well horizontally (such as adding columns). In such scenarios, some of the alternative models provide more computationally effective solutions at scale.\n",
    "\n",
    "#### Additional Resources\n",
    "Check out https://db-engines.com/en/ranking for a ranking of various databases as well as much more information about them!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MongoDB\n",
    "- non-structured database\n",
    "- JSON basis of MongoDB format\n",
    "- objects\n",
    "    - string keys and values {'key':value}\n",
    "    - like pyhton dictionaries\n",
    "- arrays\n",
    "    - series of values [value1, value2, valuen]\n",
    "    - like python lists\n",
    "    \n",
    "#### framework (top -> bottom)\n",
    "- Database\n",
    "    - JSON (objects), Python (dics)\n",
    "- Collections\n",
    "    - JSON (arrays), Python (lists)\n",
    "- Documents\n",
    "    - JSON (objects), Python (dics)\n",
    "- Subdocuments\n",
    "    - JSON (objects), Python (dics)\n",
    "- values\n",
    "    - JSON (value types), Python (value types + datetime and regex)\n",
    "\n",
    "#### importing a database\n",
    "\n",
    "        import requests\n",
    "        from pymongo import MongoClient\n",
    "        \n",
    "#### listing database and collection names\n",
    "\n",
    "        # Save a list of names of the databases managed by client\n",
    "        db_names = client.list_database_names()\n",
    "        print(db_names)\n",
    "\n",
    "        # Save a list of names of the collections managed by the \"nobel\" database\n",
    "        nobel_coll_names = client.nobel.list_collection_names()\n",
    "        print(nobel_coll_names)\n",
    "        \n",
    "#### find_one document per collection and list the fields\n",
    "\n",
    "        # Connect to the \"nobel\" database\n",
    "        db = client.nobel\n",
    "\n",
    "        # Retrieve sample prize and laureate documents\n",
    "        prize = db.prizes.find_one()\n",
    "        laureate = db.laureates.find_one()\n",
    "\n",
    "        # Print the sample prize and laureate documents\n",
    "        print(prize)\n",
    "        print(laureate)\n",
    "        print(type(laureate))\n",
    "\n",
    "        # Get the fields present in each type of document using their keys\n",
    "        prize_fields = list(prize.keys())\n",
    "        laureate_fields = list(laureate.keys())\n",
    "\n",
    "        print(prize_fields)\n",
    "        print(laureate_fields)\n",
    "\n",
    "#### count_documents\n",
    "- counts documents in a collection\n",
    "\n",
    "        #count documents example\n",
    "        count = db.laureates.count_documents()\n",
    "        print(count)\n",
    "\n",
    "#### query operators\n",
    "- filters queries\n",
    "- can add as many filters as needed\n",
    "- strings are compared lexicographically\n",
    "\n",
    "        # basic key:value filter\n",
    "        criteria = {'diedCountry': 'USA'}\n",
    "        \n",
    "        #using operators to filter\n",
    "        'field_name' = {\n",
    "            $operator1: value1,\n",
    "            $operator2: value2}\n",
    "            \n",
    "#### using dot notation\n",
    "- accesses field values\n",
    "- also access value counts (field.2) = has three values\n",
    "\n",
    "        # Filter for laureates born in Austria with non-Austria prize affiliation\n",
    "        criteria = {'bornCountry': 'Austria',                 'prizes.affiliations.country': {\"$ne\": 'Austria'}}\n",
    "\n",
    "        # Filter for laureates with at least three prizes\n",
    "        criteria = {'prizes.2': {'$exists': True}}\n",
    "        \n",
    "#### distinct()\n",
    "- collect a set of values across all documents\n",
    "- can use aggregates\n",
    "\n",
    "        # using aggregate to compare\n",
    "        countries = set(db.laureates.distinct('diedCountry')) - set(db.laureates.distinct('bornCountry'))\n",
    "        \n",
    "        #using aggregate and dot notation as value\n",
    "        count = len(db.laureates.distinct('prizes.affiliations.country'))\n",
    "        print(count)\n",
    "        \n",
    "##### using filters along with distinct\n",
    "     db.laureates.distinct('prizes.affiliations.country', {'bornCountry': 'USA'})\n",
    "     \n",
    "##### using filters along with arrays\n",
    "- can use arrays to filter data\n",
    "\n",
    "        criteria = {'diedCountry': ['USA', Canada, Mexico]}\n",
    "        \n",
    "##### '$elemMatch'\n",
    "- separates field queries so that more specific outputs can be made\n",
    "\n",
    "        # Save a filter for laureates with unshared prizes\n",
    "        unshared = {\n",
    "            \"prizes\": {\"$elemMatch\": {\n",
    "                \"category\": {\"$nin\": [\"physics\", \"chemistry\", \"medicine\"]},\n",
    "                \"share\": \"1\",\n",
    "                \"year\": {\"$gte\": \"1945\"},\n",
    "            }}}\n",
    "            \n",
    "##### Regex\n",
    "- used to find specific pattern text within a field\n",
    "- find the beginning use ^\n",
    "- use \\ to escape\n",
    "- find the end use '$'\n",
    "\n",
    "        from bson.regex import Regex\n",
    "        # Filter for laureates with \"Germany\" in their \"bornCountry\" value\n",
    "        criteria = {\"bornCountry\": Regex('Germany')}\n",
    "        print(set(db.laureates.distinct(\"bornCountry\", criteria)))    $\n",
    "\n",
    "\n",
    "#### Projection\n",
    "- reducing multi-dimensional data\n",
    "- includes fields ('field_name'=1)\n",
    "- '_id' is included by default _\n",
    "- returns results as a cursor that can be shown as a list (can slice and use list comprehension)\n",
    "\n",
    "        # project year and category, and sort\n",
    "        docs = db.prizes.find(\n",
    "                filter={},\n",
    "                projection={\"year\":1, \"category\":1, \"_id\":0},\n",
    "\n",
    "           \n",
    "#### Sorting\n",
    "- can use python sorted function\n",
    "- can also pass sort argument to the .find() function ['field_name':, 1] (asc) ['field_name':, -1] (desc)\n",
    "\n",
    "        #using python language\n",
    "        from operator import itemgetter\n",
    "\n",
    "        def all_laureates(prize):  \n",
    "          # sort the laureates by surname\n",
    "          sorted_laureates = sorted(laureate[\"surname\"], key=itemgetter('surname'))\n",
    "\n",
    "          # extract surnames\n",
    "          surnames = [laureate[\"surname\"] for laureate in sorted_laureates]\n",
    "\n",
    "          # concatenate surnames separated with \" and \" \n",
    "          all_names = \" and \".join(surnames)\n",
    "\n",
    "          return all_names\n",
    "\n",
    "        # test the function on a sample doc\n",
    "        print(all_laureates(sample_prize))\n",
    "        \n",
    "        # find physics prizes, project year and name, and sort by year\n",
    "        docs = db.prizes.find(\n",
    "                   filter= {\"category\": \"physics\"}, \n",
    "                   projection= [\"year\", \"laureates.firstname\", \"laureates.surname\"], \n",
    "                   sort= [(\"year\", 1)])\n",
    "                   \n",
    "### create_index()\n",
    "- similar to a book index\n",
    "- use with a very specific query\n",
    "- use with large collections\n",
    "- can index before a query to further specify\n",
    "- other index features\n",
    "    - index_information() - confirms which indexes exist on a specified collection\n",
    "    - explain() - provides the output of how a query will perform\n",
    "    \n",
    "            # Specify an index model for compound sorting\n",
    "            index_model = [(\"category\", 1), (\"year\", -1)]\n",
    "            db.prizes.create_index(index_model)\n",
    "            \n",
    "#### Limit and Skip \n",
    "- limit and skip are parameters to include in the .find() and .find_one() method\n",
    "- limit will show top n\n",
    "- skip will skip every n \n",
    "\n",
    "        #skip every three, limit to 8\n",
    "        db.laureates.find(\"prizes\", skip=3, limit=8)\n",
    "        #dot notation\n",
    "        db.laureates.find_one(\"prizes\").skip(3).limit(8)\n",
    "        \n",
    "#### aggregate()\n",
    "- uses a key/value operation pairs format to imply stages to a query\n",
    "- can pass expression objects\n",
    "- can also pass operaters as expressions\n",
    "\n",
    "        # Translate cursor to aggregation pipeline\n",
    "        pipeline = [\n",
    "            {'$match': {'gender': {'$ne': 'org'}}},\n",
    "            {'$project': {\"bornCountry\": 1, \"prizes.affiliations.country\": 1}},\n",
    "            {'$limit': 3}\n",
    "            \n",
    "##### $$unwind\n",
    "- outputs one pipeline document per array element\n",
    "- replaces projecting sizes and summing over them\n",
    "\n",
    "##### $$lookup\n",
    "- pulls in docs from another collection via a left outer join\n",
    "\n",
    "##### $$addfield\n",
    "- allows to add customized query fields to pipeline\n",
    "\n",
    "##### $$bucket\n",
    "- groups values into buckets defined by a sequence of boundaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
