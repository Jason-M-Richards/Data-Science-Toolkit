{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "Purposes:\n",
    "- visualize unseen objects\n",
    "- sharpen and restore images\n",
    "- seek for the image of interest\n",
    "- measure image patterns\n",
    "- image recognition\n",
    "\n",
    "### What is an image\n",
    "\n",
    " - 2d matrix array of pixels\n",
    " - greyscale and RGB\n",
    " - greyscale only has 255 possible intensities per pixel\n",
    " - RGB has red, blue and green intensities per pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sci-kit Image\n",
    "\n",
    "### Load image and convert color to grayscale\n",
    "\n",
    "    # Import the modules from skimage\n",
    "    from skimage import data, color\n",
    "\n",
    "    # Load the rocket image\n",
    "    rocket = data.rocket()\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray_scaled_rocket = color.rgb2gray(rocket)\n",
    "\n",
    "    # Show the original image\n",
    "    show_image(rocket, 'Original RGB image')\n",
    "\n",
    "    # Show the grayscale image\n",
    "    show_image(gray_scaled_rocket, 'Grayscale image')\n",
    "    \n",
    "### Thresholding\n",
    "\n",
    "- converts greyscale to black and white\n",
    "- isolates objects\n",
    "- categories\n",
    "    - global or histogram based (good for uniform backgrounds)\n",
    "    - local or adaptive (good for uneven background illumination)\n",
    "\n",
    "#### global threshold\n",
    "\n",
    "    # Import the otsu threshold function\n",
    "    from skimage.filters import threshold_otsu\n",
    "\n",
    "    # Make the image grayscale using rgb2gray\n",
    "    chess_pieces_image_gray = rgb2gray(chess_pieces_image)\n",
    "\n",
    "    # Obtain the optimal threshold value with otsu\n",
    "    thresh = threshold_otsu(chess_pieces_image_gray)\n",
    "\n",
    "    # Apply thresholding to the image\n",
    "    binary = chess_pieces_image_gray > thresh\n",
    "\n",
    "    # Show the image\n",
    "    show_image(binary, 'Binary image')\n",
    "    \n",
    "#### local threshold\n",
    "\n",
    "    # Import the local threshold function\n",
    "    from skimage.filters import threshold_local\n",
    "\n",
    "    # Set the block size to 35 pixels\n",
    "    block_size = 35\n",
    "\n",
    "    # Obtain the optimal local thresholding\n",
    "    local_thresh = threshold_local(page_image, block_size, offset=10)\n",
    "\n",
    "    # Obtain the binary image by applying local thresholding\n",
    "    binary_local = page_image > local_thresh\n",
    "\n",
    "    # Show the binary image\n",
    "    show_image(binary_local, 'Local thresholding')\n",
    "    \n",
    "#### all thresholds option\n",
    "\n",
    "    # Import the try all function\n",
    "    from skimage.filters import try_all_threshold\n",
    "\n",
    "    # Import the rgb to gray convertor function \n",
    "    from skimage.color import rgb2gray\n",
    "\n",
    "    # Turn the fruits image to grayscale\n",
    "    grayscale = rgb2gray(fruits_image)\n",
    "\n",
    "    # Use the try all method on the grayscale image\n",
    "    fig, ax = try_all_threshold(grayscale, verbose=False)\n",
    "\n",
    "    # Show the resulting plots\n",
    "    plt.show()\n",
    "    \n",
    "### Filtering\n",
    "\n",
    "- enhances image\n",
    "- emphasize and remove features\n",
    "- smoothing\n",
    "- sharpening\n",
    "- edge detection\n",
    "\n",
    "#### edge detection\n",
    "\n",
    "    # Import the color module\n",
    "    from skimage import color\n",
    "\n",
    "    # Import the filters module and sobel function\n",
    "    from skimage.filters import sobel\n",
    "\n",
    "    # Make the image grayscale\n",
    "    soaps_image_gray = color.rgb2gray(soaps_image)\n",
    "\n",
    "    # Apply edge detection filter\n",
    "    edge_sobel = sobel(soaps_image_gray)\n",
    "\n",
    "    # Show original and resulting image to compare\n",
    "    show_image(soaps_image, \"Original\")\n",
    "    show_image(edge_sobel, \"Edges with Sobel\")\n",
    "    \n",
    "#### edge detction with Canny\n",
    "\n",
    "- better performing than sobel\n",
    "- setting sigma can adjust edge detection (lower sigma = greater edge sensitivity)\n",
    "\n",
    "        # Import the canny edge detector \n",
    "        from skimage.feature import canny\n",
    "\n",
    "        # Convert image to grayscale\n",
    "        grapefruit = color.rgb2gray(grapefruit)\n",
    "\n",
    "       # Apply canny edge detector with a sigma of 1.8\n",
    "        edges_1_8 = canny(grapefruit, sigma=1.8)\n",
    "\n",
    "        # Apply canny edge detector with a sigma of 2.2\n",
    "        edges_2_2 = canny(grapefruit, sigma=2.2)\n",
    "\n",
    "        # Show resulting images\n",
    "        show_image(edges_1_8, \"Sigma of 1.8\")\n",
    "        show_image(edges_2_2, \"Sigma of 2.2\")\n",
    "        #### smoothing\n",
    "\n",
    "        # Import Gaussian filter \n",
    "        from skimage.filters import gaussian\n",
    "\n",
    "        # Apply filter\n",
    "        gaussian_image = gaussian(building_image, multichannel=True)\n",
    "\n",
    "        # Show original and resulting image to compare\n",
    "        show_image(building_image, \"Original\")\n",
    "        show_image(gaussian_image, \"Reduced sharpness Gaussian\")\n",
    "    \n",
    "#### contrast enhancement\n",
    "\n",
    "- difference in intensity between highest and lowest intensity\n",
    "       \n",
    "       # find max pixel value\n",
    "        max = np.max(clock_image)\n",
    "\n",
    "        # find min pixel value\n",
    "        min = np.min(clock_image)\n",
    "        \n",
    "        contrast = max-min\n",
    "\n",
    "- contrast stretching by:\n",
    "    - histogram equalization\n",
    "    - contrast limited adaptive histogram equalization (CLAHE)\n",
    "\n",
    "##### histogram equalization\n",
    "\n",
    "    # Import the required module\n",
    "    from skimage import exposure\n",
    "\n",
    "    # Show original x-ray image and its histogram\n",
    "    show_image(chest_xray_image, 'Original x-ray')\n",
    "\n",
    "    plt.title('Histogram of image')\n",
    "    plt.hist(chest_xray_image.ravel(), bins=256)\n",
    "    plt.show()\n",
    "\n",
    "    # Use histogram equalization to improve the contrast\n",
    "    xray_image_eq =  exposure.equalize_hist(chest_xray_image)\n",
    "\n",
    "    # Show the resulting image\n",
    "    show_image(xray_image_eq, 'Resulting image')\n",
    "    \n",
    "##### adaptive equalization\n",
    "\n",
    "    # Import the necessary modules\n",
    "    from skimage import data, exposure\n",
    "\n",
    "    # Load the image\n",
    "    original_image = data.coffee()\n",
    "\n",
    "    # Apply the adaptive equalization on the original image\n",
    "    adapthist_eq_image = exposure.equalize_adapthist(original_image, clip_limit=0.03)\n",
    "\n",
    "    # Compare the original image to the equalized\n",
    "    show_image(original_image)\n",
    "    show_image(adapthist_eq_image, '#ImageProcessingDatacamp')\n",
    "    \n",
    "### Transform Images\n",
    "\n",
    "- prepping images for ML\n",
    "- optimize and compress images\n",
    "- save images with same proportion\n",
    "\n",
    "#### rotate image\n",
    "\n",
    "    # Import the module and the rotate and rescale functions\n",
    "    from skimage.transform import rotate, rescale\n",
    "\n",
    "    # Rotate the image 90 degrees clockwise \n",
    "    rotated_cat_image = rotate(image_cat, -90)\n",
    "\n",
    "#### rescale with and without aliasing\n",
    "\n",
    "        # Rescale with anti aliasing\n",
    "        rescaled_with_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=True, multichannel=True)\n",
    "\n",
    "        # Rescale without anti aliasing\n",
    "        rescaled_without_aa = rescale(rotated_cat_image, 1/4, anti_aliasing=False, multichannel=True)\n",
    "\n",
    "        # Show the resulting images\n",
    "        show_image(rescaled_with_aa, \"Transformed with anti aliasing\")\n",
    "        show_image(rescaled_without_aa, \"Transformed without anti aliasing\")\n",
    "\n",
    "#### proportional resizing\n",
    "\n",
    "    # Import the module and function\n",
    "    from skimage.transform import resize\n",
    "\n",
    "    # Set proportional height so its half its size\n",
    "    height = dogs_banner.shape([0] / 2)\n",
    "    width = dogs_banner.shape([1] / 2)\n",
    "\n",
    "    # Resize using the calculated proportional height and width\n",
    "    image_resized = resize(dogs_banner, (height, width),\n",
    "                           anti_aliasing=True)\n",
    "\n",
    "    # Show the original and rotated image\n",
    "    show_image(dogs_banner, 'Original')\n",
    "    show_image(image_resized, 'Resized image')\n",
    "    \n",
    "### Morphology\n",
    "\n",
    "- best for binary images\n",
    "- dilate (adds pixels to object boundaries)\n",
    "- erosion (removes pixels on object boundaries)\n",
    "- set using a structuring element\n",
    "\n",
    "#### erosion\n",
    "\n",
    "    # Import the morphology module\n",
    "    from skimage import morphology\n",
    "\n",
    "    # Obtain the eroded shape \n",
    "    eroded_image_shape = morphology.binary_erosion(upper_r_image) \n",
    "\n",
    "#### dilation\n",
    "\n",
    "    # Import the module\n",
    "    from skimage import morphology\n",
    "\n",
    "    # Obtain the dilated image \n",
    "    dilated_image = morphology.binary_dilation(world_image)\n",
    "\n",
    "    # See results\n",
    "    show_image(world_image, 'Original')\n",
    "    show_image(dilated_image, 'Dilated image')\n",
    "    \n",
    "### Image Restoration\n",
    "\n",
    "- fix damaged images\n",
    "- remove text, logo, objects\n",
    "- AKA Inpainting\n",
    "- damaged pixels set as a mask\n",
    "\n",
    "        # Import the module from restoration\n",
    "        from skimage.restoration import inpaint\n",
    "        \n",
    "        # Initialize the mask\n",
    "        mask = np.zeros(image_with_logo.shape[:-1])\n",
    "\n",
    "        # Show the defective image\n",
    "        show_image(defect_image, 'Image to restore')\n",
    "        \n",
    "        # Set the pixels where the logo is to 1\n",
    "        mask[210:272, 360:425] = 1\n",
    "\n",
    "        # Apply inpainting to remove the logo\n",
    "        image_logo_removed = inpaint.inpaint_biharmonic(image_with_logo,\n",
    "                                          mask,\n",
    "                                          multichannel=True)\n",
    "\n",
    "        # Show the original and logo removed images\n",
    "        show_image(image_with_logo, 'Image with logo')\n",
    "        show_image(image_logo_removed, 'Image with logo removed')\n",
    "        \n",
    "### Noise\n",
    "\n",
    "- errors in image processing\n",
    "- can add random noise\n",
    "- remove noise\n",
    "    - total variation filter TV)\n",
    "    - Bilateral\n",
    "    - Wavelet\n",
    "    - non-local means\n",
    "    \n",
    "#### add noise\n",
    "\n",
    "    # Import the module and function\n",
    "    from skimage.util import random_noise\n",
    "\n",
    "    # Add noise to the image\n",
    "    noisy_image = random_noise(fruit_image)\n",
    "\n",
    "    # Show original and resulting image\n",
    "    show_image(fruit_image, 'Original')\n",
    "    show_image(noisy_image, 'Noisy image')\n",
    "\n",
    "#### denoise (TV)\n",
    "\n",
    "- smoother (less edges)\n",
    "\n",
    "        # Import the module and function\n",
    "        from skimage.restoration import denoise_tv_chambolle\n",
    "\n",
    "        # Apply total variation filter denoising\n",
    "        denoised_image = denoise_tv_chambolle(noisy_image, \n",
    "                                              multichannel=True)\n",
    "\n",
    "        # Show the noisy and denoised images\n",
    "        show_image(noisy_image, 'Noisy')\n",
    "        show_image(denoised_image, 'Denoised image')\n",
    "        \n",
    "#### denoise (Bilateral)\n",
    "\n",
    "- less smoothness, more edges\n",
    "\n",
    "        # Import bilateral denoising function\n",
    "        from skimage.restoration import denoise_bilateral\n",
    "\n",
    "        # Apply bilateral filter denoising\n",
    "        denoised_image = denoise_bilateral(landscape_image, \n",
    "                                           multichannel=True)\n",
    "\n",
    "        # Show original and resulting images\n",
    "        show_image(landscape_image, 'Noisy image')\n",
    "        show_image(denoised_image, 'Denoised image')\n",
    "        \n",
    "### Segmentation\n",
    "\n",
    "- grouping pixels (superpixel) to segment \n",
    "- more meaningful regions\n",
    "- computational eficiency\n",
    "- supervised segmentation\n",
    "    - using thresholds\n",
    "- unsupervised segmentation\n",
    "    - simple linear iterative clustering (SLIC)\n",
    "    \n",
    "            # Import the slic function from segmentation module\n",
    "            from skimage.segmentation import slic\n",
    "\n",
    "            # Import the label2rgb function from color module\n",
    "            from skimage.color import label2rgb\n",
    "\n",
    "            # Obtain the segmentation with 400 regions\n",
    "            segments = slic(face_image, n_segments = 400)\n",
    "            \n",
    "            # Obtain segmented image using label2rgb\n",
    "            segmented_image = label2rgb(segments, profile_image, kind='avg'),\n",
    "            \n",
    "- classify shapes\n",
    "- determine the number of objects\n",
    "- input should be a binary image (after thresholding)\n",
    "- constant level value\n",
    "    - 0 - 1, higher value is more sensitive\n",
    "    \n",
    "            # Make the image grayscale\n",
    "            image_dices = color.rgb2gray(image_dices)\n",
    "\n",
    "            # Obtain the optimal thresh value\n",
    "            thresh = filters.threshold_otsu(image_dices)\n",
    "\n",
    "            # Apply thresholding\n",
    "            binary = image_dices > thresh\n",
    "\n",
    "            # Find contours at a constant value of 0.8\n",
    "            contours = measure.find_contours(binary, 0.8)\n",
    "\n",
    "            # Show the image\n",
    "            show_image_contour(image_dices, contours)\n",
    "\n",
    "#### getting contour counts\n",
    "\n",
    "    # Create list with the shape of each contour\n",
    "    shape_contours = [cnt.shape[0] for cnt in contours]\n",
    "\n",
    "    # Set 50 as the maximum size of the dots shape\n",
    "    max_dots_shape = 50\n",
    "\n",
    "    # Count dots in contours excluding bigger than dots size\n",
    "    dots_contours = [cnt for cnt in contours if np.shape(cnt)[0] < max_dots_shape]\n",
    "\n",
    "    # Shows all contours found \n",
    "    show_image_contour(binary, contours)\n",
    "\n",
    "    # Print the dice's number\n",
    "    print(\"Dice's dots number: {}. \".format(len(dots_contours)))\n",
    "    \n",
    "### Corner Detection\n",
    "\n",
    "- Harris corner detector\n",
    "\n",
    "        # Import the corner detector related functions and module\n",
    "        from skimage.feature import corner_harris, corner_peaks\n",
    "\n",
    "        # Convert image from RGB-3 to grayscale\n",
    "        building_image_gray = color.rgb2gray(building_image)\n",
    "\n",
    "        # Apply the detector  to measure the possible corners\n",
    "        measure_image = corner_harris(building_image_gray)\n",
    "\n",
    "        # Find the peaks of the corners using the Harris detector\n",
    "        coords = corner_peaks(measure_image, min_distance=2)\n",
    "\n",
    "        # Show original and resulting image with corners detected\n",
    "        show_image(building_image, \"Original\")\n",
    "        show_image_with_corners(building_image, coords)\n",
    "        \n",
    "### Face Detection\n",
    "\n",
    "- add filters\n",
    "- auto focus\n",
    "- recommendations\n",
    "- blur for privacy protection\n",
    "- recognize emotions\n",
    "- step ratio sets the exhaustive state of the search (1 = exhaustive, > 1, less exhaustive)\n",
    "\n",
    "        # since this is machine learning, a trained file needs fit first\n",
    "        # Load the trained file from data\n",
    "        trained_file = data.lbp_frontal_face_cascade_filename()\n",
    "\n",
    "        # Initialize the detector cascade\n",
    "        detector = Cascade(trained_file)\n",
    "\n",
    "        # Detect faces with scale factor to 1.2 and step ratio to 1\n",
    "        detected = detector.detect_multi_scale(img=friends_image,\n",
    "                                               scale_factor=1.2,\n",
    "                                               step_ratio=1,\n",
    "                                               min_size=(10, 10),\n",
    "                                               max_size=(200, 200))\n",
    "        # Show the detected faces\n",
    "        show_detected_face(friends_image, detected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy for Images\n",
    "\n",
    "- flip images\n",
    "- extraxting features\n",
    "- images are multidimensional arrays (color photos)\n",
    "- get shapes and pixel counts\n",
    "\n",
    "### vertical flip\n",
    "\n",
    "    # Flip the image vertically\n",
    "    seville_vertical_flip = np.flipud(flipped_seville)\n",
    "    \n",
    "### horizontal flip\n",
    "\n",
    "    # Flip the previous image horizontally\n",
    "    seville_horizontal_flip = np.fliplr(seville_vertical_flip)\n",
    "\n",
    "### show image\n",
    "\n",
    "    # Show the resulting image\n",
    "    show_image(seville_horizontal_flip, 'Seville')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms for Images\n",
    "\n",
    "- used to show intensities of each color\n",
    "- color represented in last last part of array\n",
    "    - red = [:,:,0]\n",
    "    - green = [:,:,1]\n",
    "    - blue = [;,;,2]\n",
    "\n",
    "            # Obtain the red channel\n",
    "            red_channel = image[:, :, 0]\n",
    "\n",
    "            # Plot the red histogram with bins in a range of 256\n",
    "            plt.hist(red_channel.ravel(), bins=256)\n",
    "\n",
    "            # Set title and show\n",
    "            plt.title('Red Histogram')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy Protection with Skimage\n",
    "\n",
    "    # Detect the faces\n",
    "    detected = detector.detect_multi_scale(img=group_image, \n",
    "                                           scale_factor=1.2, step_ratio=1, \n",
    "                                           min_size=(10,10), max_size=(100, 100))\n",
    "    # For each detected face\n",
    "    for d in detected:  \n",
    "        # Obtain the face rectangle from detected coordinates\n",
    "        face = getFaceRectangle(d)\n",
    "\n",
    "        # Apply gaussian filter to extracted face\n",
    "        blurred_face = gaussian(face, multichannel=True, sigma = 8)\n",
    "\n",
    "        # Merge this blurry face to our final image and show it\n",
    "        resulting_image = mergeBlurryFace(group_image, blurred_face) \n",
    "    show_image(resulting_image, \"Blurred faces\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photo Restore with Skimage\n",
    "\n",
    "    # Import the necessary modules\n",
    "    from skimage.restoration import denoise_tv_chambolle, inpaint\n",
    "    from skimage import transform\n",
    "\n",
    "    # Transform the image so it's not rotated\n",
    "    upright_img = rotate(damaged_image, 20)\n",
    "\n",
    "    # Remove noise from the image, using the chambolle method\n",
    "    upright_img_without_noise = denoise_tv_chambolle(upright_img,weight=0.1, multichannel=True)\n",
    "\n",
    "    # Reconstruct the image missing parts\n",
    "    mask = get_mask(upright_img)\n",
    "    result = inpaint.inpaint_biharmonic(upright_img_without_noise, mask, multichannel=True)\n",
    "\n",
    "    show_image(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
