{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Basics\n",
    "\n",
    "- grouping items together with similar characteristics\n",
    "- items in groups similar to each other than in other groups\n",
    "- unsupervised learning\n",
    "- examples\n",
    "    - news articles\n",
    "    - customer segmentation\n",
    "    \n",
    "#### Types of Clustering Algorithms\n",
    "\n",
    "- Heirarchal\n",
    "- K means\n",
    "- DBSCAN\n",
    "- Gaussian Methods\n",
    "\n",
    "#### Data Prep\n",
    "\n",
    "- different units $_$, cm, feet\n",
    "-  different scales km, mm\n",
    "-  data to be normalized\n",
    "\n",
    "##### whiten\n",
    "\n",
    "- scipy package to normalize data\n",
    "\n",
    "        # Import the whiten function\n",
    "        from scipy.cluster.vq import whiten\n",
    "\n",
    "        goals_for = [4,3,2,3,1,1,2,0,1,4]\n",
    "\n",
    "        # Use the whiten() function to standardize the data\n",
    "        scaled_data = whiten(goals_for)\n",
    "        print(scaled_data)\n",
    "        # Plot original data\n",
    "        plt.plot(goals_for, label='original')\n",
    "\n",
    "        # Plot scaled data\n",
    "        plt.plot(scaled_data, label='scaled')\n",
    "\n",
    "        # Show the legend in the plot\n",
    "        plt.legend()\n",
    "\n",
    "        # Display the plot\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heirarchal Clustering\n",
    "\n",
    "#### linkage\n",
    "\n",
    "- measures the distance between objects\n",
    "    - method= how to calculate proximity between clusters\n",
    "        - no right method for problems\n",
    "        - understand the data before selecting a method\n",
    "        - single - based on two closest objects\n",
    "        - complete - based on two farthest objects\n",
    "        - average - based on the arithmetic mean of objects\n",
    "        - centroid - based on the geometric mean of objects\n",
    "        - median - uses the median of objects\n",
    "        - ward - based on sum squares\n",
    "    - metric= distance metric\n",
    "    - optimal_ordering= ordering data points\n",
    "    \n",
    "#### fcluster\n",
    "\n",
    "- creates the cluster labels\n",
    "    - distance_matrix= output of linkage() method\n",
    "    - num_clusters= number of clusters\n",
    "    - criterion= how to decide thresholds to form clusters\n",
    "    \n",
    "            # Import linkage and fcluster functions\n",
    "            from scipy.cluster.hierarchy import linkage, fcluster\n",
    "\n",
    "            # Use the linkage() function to compute distance\n",
    "            Z = linkage(df, 'ward')\n",
    "\n",
    "            # Generate cluster labels\n",
    "            df['cluster_labels'] = fcluster(Z, #of clusters, criterion='maxclust')\n",
    "\n",
    "            # Plot the points with seaborn\n",
    "            sns.scatterplot(x='x', y='y', hue='cluster_labels', data=df)\n",
    "            plt.show()\n",
    "            \n",
    "#### Limitations\n",
    "- linkage method takes longer as datapoints increase exponentially\n",
    "- infeasible for large datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans Clustering\n",
    "\n",
    "- clusters faster than hierarchal\n",
    "\n",
    "#### kmeans()\n",
    "\n",
    "- obs - standardized observations\n",
    "- k_or_guess - number of clusters\n",
    "- iter - number of iterations (default 20)\n",
    "- thresh - threshold (default 1e-05)\n",
    "- check_finite - bbolean whether to check if observations contain only finite numbers\n",
    "- returns cluster centers, distortion\n",
    "\n",
    "##### distortion\n",
    "\n",
    "- sum of squares of distances of points from cluster centers\n",
    "- distortion decreases with increasing # of clusters (zero when == # of points)\n",
    "\n",
    "#### vq()\n",
    "\n",
    "- generates cluster labels\n",
    "- obs - standardized observations\n",
    "- code_book - cluster centers\n",
    "- check_finite - boolean whether to check if observations contain only finite numbers\n",
    "- returns list of cluster labels, list of distortions\n",
    "\n",
    "        # Import the kmeans and vq functions\n",
    "        from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "        # Generate cluster centers\n",
    "        cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']], 2)\n",
    "\n",
    "        # Assign cluster labels\n",
    "        comic_con['cluster_labels'], distortion_list = vq(comic_con[['x_scaled', 'y_scaled']],code_book=cluster_centers)\n",
    "\n",
    "        # Plot clusters\n",
    "        sns.scatterplot(x='x_scaled', y='y_scaled', \n",
    "                        hue='cluster_labels', data = comic_con)\n",
    "        plt.show()\n",
    "        \n",
    "#### Limits of kmeans\n",
    "\n",
    "- how to find the right # of clusters\n",
    "- impact of multiple random seeds\n",
    "- biased towards equal sized clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "#### scatterplots\n",
    "- provides a good initial look at potential cluster formations\n",
    "- try to make sense of the clusters formed\n",
    "- spot trends in the data\n",
    "\n",
    "##### matplotlib\n",
    "\n",
    "        # Matplotlib method with color assignment\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        # Define a colors dictionary for clusters\n",
    "        colors = {1:'red', 2:'blue'}\n",
    "\n",
    "        # Plot a scatter plot\n",
    "        comic_con.plot.scatter(x = 'x_scaled', \n",
    "                               y = 'y_scaled',\n",
    "                               c = comic_con['cluster_labels'].apply(lambda x: colors[x]))\n",
    "        plt.show()\n",
    "        \n",
    "##### seaborn  \n",
    "\n",
    "        # Seaborn method using cluster labels as color\n",
    "        import seaborn as sns\n",
    "\n",
    "        # Plot a scatter plot using seaborn\n",
    "        sns.scatterplot(x='x_scaled', \n",
    "                        y='y_scaled', \n",
    "                        hue='cluster_labels', \n",
    "                        data = comic_con)\n",
    "        plt.show()\n",
    "        \n",
    "##### dendrograms\n",
    "\n",
    "- shows progressions as clusters emerge\n",
    "- branching diagram\n",
    "- can assist in deciding how many clusters to decide on\n",
    "\n",
    "        # Import the dendrogram function\n",
    "        from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "        # Create a dendrogram\n",
    "        dn = dendrogram(distance_matrix)\n",
    "\n",
    "        # Display the dendogram\n",
    "        plt.show()\n",
    "        \n",
    "#### Elbow charts\n",
    "\n",
    "- helps in determing # of clusters in k-means clustering\n",
    "- x = # of clusters, y = distortion\n",
    "- only gives _indication_ of optimal clusters\n",
    "\n",
    "        distortions = []\n",
    "        num_clusters = range(1, 7)\n",
    "\n",
    "        # Create a list of distortions from the kmeans function\n",
    "        for i in num_clusters:\n",
    "            cluster_centers, distortion = kmeans(comic_con[['x_scaled', 'y_scaled']],i)\n",
    "            distortions.append(distortion)\n",
    "\n",
    "        # Create a data frame with two lists - num_clusters, distortions\n",
    "        elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})\n",
    "\n",
    "        # Creat a line plot of num_clusters and distortions\n",
    "        sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "        plt.xticks(num_clusters)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other methods to determine optimal clusters\n",
    "\n",
    "####  Average Silhouette\n",
    "\n",
    "#### Gap Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Example (Dominant Colors)\n",
    "\n",
    "    # Import image class of matplotlib\n",
    "    import matplotlib.image as img\n",
    "\n",
    "    # Read batman image and print dimensions\n",
    "    batman_image = img.imread('batman.jpg')\n",
    "    print(batman_image.shape)\n",
    "\n",
    "    # Store RGB values of all pixels in lists r, g and b\n",
    "    for row in batman_image:\n",
    "        for temp_r, temp_g, temp_b in row:\n",
    "            r.append(temp_r)\n",
    "            g.append(temp_g)\n",
    "            b.append(temp_b)\n",
    "    distortions = []\n",
    "    \n",
    "    num_clusters = range(1, 7)\n",
    "\n",
    "    # Create a list of distortions from the kmeans function\n",
    "    for i in num_clusters:\n",
    "        cluster_centers, distortion = kmeans(batman_df[['scaled_red', 'scaled_blue', 'scaled_green']], i)\n",
    "        distortions.append(distortion)\n",
    "\n",
    "    # Create a data frame with two lists, num_clusters and distortions\n",
    "    elbow_plot = pd.DataFrame({'num_clusters': num_clusters, 'distortions': distortions})\n",
    "\n",
    "    # Create a line plot of num_clusters and distortions\n",
    "    sns.lineplot(x='num_clusters', y='distortions', data = elbow_plot)\n",
    "    plt.xticks(num_clusters)\n",
    "    plt.show()\n",
    "    \n",
    "    # Get standard deviations of each color\n",
    "    r_std, g_std, b_std = batman_df[['red', 'green', 'blue']].std()\n",
    "\n",
    "    for cluster_center in cluster_centers:\n",
    "        scaled_r, scaled_g, scaled_b = cluster_center\n",
    "        # Convert each standardized value to scaled value\n",
    "        colors.append((\n",
    "            scaled_r * r_std / 255,\n",
    "            scaled_g * g_std / 255,\n",
    "            scaled_b * b_std / 255\n",
    "        ))\n",
    "\n",
    "    # Display colors of cluster centers\n",
    "    plt.imshow([colors])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Example (Document)\n",
    "\n",
    "    # Import TfidfVectorizer class from sklearn\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "    # Initialize TfidfVectorizer\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.75, max_features=50, tokenizer= remove_noise)\n",
    "\n",
    "    # Use the .fit_transform() method on the list plots\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(plots)\n",
    "    \n",
    "    num_clusters = 2\n",
    "\n",
    "    # Generate cluster centers through the kmeans function\n",
    "    cluster_centers, distortion = kmeans(tfidf_matrix.todense(), num_clusters)\n",
    "\n",
    "    # Generate terms from the tfidf_vectorizer object\n",
    "    terms = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "    for i in range(num_clusters):\n",
    "        # Sort the terms and print top 3 terms\n",
    "        center_terms = dict(zip(terms, list(cluster_centers[i])))\n",
    "        sorted_terms = sorted(center_terms, key=center_terms.get, reverse=True)\n",
    "        print(sorted_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Example (Multiple Features)\n",
    "- consider feature reduction using factor analysis or multidimensional scaling\n",
    "\n",
    "            # Print the size of the clusters\n",
    "        print(fifa.groupby('cluster_labels')['ID'].count())\n",
    "\n",
    "        # Print the mean value of wages in each cluster\n",
    "        print(fifa.groupby('cluster_labels')['eur_wage'].mean())\n",
    "        \n",
    "        # Create centroids with kmeans for 2 clusters\n",
    "        cluster_centers,_ = kmeans(fifa[scaled_features], 2)\n",
    "        \n",
    "        # Create centroids with kmeans for 2 clusters\n",
    "        cluster_centers,_ = kmeans(fifa[scaled_features], 2)\n",
    "\n",
    "        # Assign cluster labels and print cluster centers\n",
    "        fifa['cluster_labels'], _ = vq(fifa[scaled_features], cluster_centers)\n",
    "        print(fifa.groupby('cluster_labels')[scaled_features].mean())\n",
    "        \n",
    "        # Plot cluster centers to visualize clusters\n",
    "        fifa.groupby('cluster_labels')[scaled_features].mean().plot(legend=True, kind='bar')\n",
    "        plt.show()\n",
    "        \n",
    "        # Get the name column of top 5 players in each cluster\n",
    "        for cluster in fifa['cluster_labels'].unique():\n",
    "            print(cluster, fifa[fifa['cluster_labels'] == cluster]['name'].values[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "139.489px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
